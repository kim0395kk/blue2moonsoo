# streamlit_app.py â€” AI í–‰ì •ê´€ Pro (v8.1) "Click-to-Verify" + Performance Lab
# âœ… ëª©í‘œ
# - ë²•ì ê·¼ê±°: í›„ë³´ ë¦¬ìŠ¤íŠ¸ â†’ í´ë¦­ â†’ (1) ì›ë¬¸ ì¡°ë¬¸ (2) ê´€ë ¨ ì‚¬ë¡€(ë‰´ìŠ¤/ì›¹) ë¥¼ í•œ í™”ë©´ì—ì„œ í™•ì¸
# - ê³µë¬¸: A4 ìš©ì§€ ëŠë‚Œ HTML ë Œë” + HTML ë‹¤ìš´ë¡œë“œ
# - ì„±ëŠ¥: requests.Session ì¬ì‚¬ìš© + cache_data + ì„±ëŠ¥ ì‹¤í—˜ì‹¤(p50/p95/ë©”ëª¨ë¦¬) íƒ­
# - ì•ˆì •ì„±: U+EA01 ê°™ì€ ë¹„í‘œì‹œ ë¬¸ì ì œê±°, Optional imports, ì‹¤íŒ¨ ì‹œ graceful fallback
#
# -------------------------------
# secrets.toml (Streamlit Cloud)
# -------------------------------
# [general]
# GROQ_API_KEY = "..."
# GROQ_MODEL_FAST = "qwen/qwen3-32b"
# GROQ_MODEL_STRICT = "llama-3.3-70b-versatile"
#
# [law]
# LAW_API_ID = "..."  # law.go.kr DRF OC ê°’
#
# [naver]
# CLIENT_ID = "..."
# CLIENT_SECRET = "..."
#
# [supabase]  # ì˜µì…˜(ë¡œê·¸/íˆìŠ¤í† ë¦¬)
# SUPABASE_URL = "https://xxxx.supabase.co"
# SUPABASE_KEY = "service_role_or_anon_key"
#
# -------------------------------
# requirements.txt (ê¶Œì¥)
# -------------------------------
# streamlit
# groq
# requests
# xmltodict
# python-dateutil
# pandas
# (optional) orjson msgspec supabase

import json
import re
import time
import statistics
import tracemalloc
from dataclasses import dataclass
from datetime import datetime
from html import escape, unescape
from time import perf_counter_ns
from typing import Any, Dict, List, Optional, Tuple

import streamlit as st
import streamlit.components.v1 as components

try:
    import pandas as pd
except Exception:
    pd = None

# Optional libs
try:
    from groq import Groq
except Exception:
    Groq = None

try:
    import requests
except Exception:
    requests = None

try:
    import xmltodict
except Exception:
    xmltodict = None

try:
    import orjson
except Exception:
    orjson = None

try:
    import msgspec
except Exception:
    msgspec = None

try:
    from supabase import create_client
except Exception:
    create_client = None


# =========================
# 1) Page & Style
# =========================
st.set_page_config(
    layout="wide",
    page_title="AI í–‰ì •ê´€ Pro (v8.1)",
    page_icon="âš–ï¸",
    initial_sidebar_state="collapsed",
)

st.markdown(
    """
<style>
.stApp { background-color: #f8f9fa; }

/* A4 paper */
.paper-sheet {
  background: #fff; width: 100%; max-width: 210mm; min-height: 297mm;
  padding: 25mm; margin: auto; box-shadow: 0 6px 18px rgba(0,0,0,0.08);
  font-family: 'Noto Serif KR','Nanum Myeongjo',serif;
  color:#111; line-height:1.65; position:relative;
}
.doc-header { text-align:center; font-size:24pt; font-weight:800; margin-bottom:22px; letter-spacing:1px; }
.doc-info {
  display:flex; justify-content:space-between; gap:10px; flex-wrap:wrap;
  font-size:11pt; border-bottom:2px solid #111; padding-bottom:12px; margin-bottom:20px;
}
.doc-body { font-size:12pt; text-align: justify; }
.doc-footer { text-align:center; font-size:20pt; font-weight:800; margin-top:80px; letter-spacing:3px; }
.stamp {
  position:absolute; bottom:85px; right:80px; border:3px solid #d32f2f; color: #d32f2f;
  padding:6px 12px; font-size:14pt; font-weight:800; transform:rotate(-15deg);
  opacity:0.85; border-radius:4px; font-family: 'Nanum Gothic', sans-serif;
}
.small-muted { color:#6b7280; font-size:12px; }

/* Clickable list cards */
.card {
  background:#fff; border:1px solid #e5e7eb; border-radius:12px;
  padding:12px 14px; margin:10px 0; box-shadow: 0 2px 8px rgba(0,0,0,0.03);
}
.card-title { font-weight:800; font-size:15px; margin-bottom:6px; }
.card-sub { color:#374151; font-size:13px; }
.badge { display:inline-block; padding:2px 8px; border-radius:999px; font-size:12px; background:#f3f4f6; color:#111; margin-left:6px; }

/* Agent logs */
.agent-log {
  font-family: 'Pretendard', sans-serif; font-size: 0.92rem; padding: 8px 12px;
  border-radius: 8px; margin-bottom: 6px; background: white; border: 1px solid #e5e7eb;
}
.log-legal { border-left: 5px solid #3b82f6; }
.log-search { border-left: 5px solid #f97316; }
.log-strat { border-left: 5px solid #8b5cf6; }
.log-draft { border-left: 5px solid #ef4444; }
.log-sys   { border-left: 5px solid #9ca3af; }

.ev-card{
  background:#fff; border:1px solid #e5e7eb; border-radius:10px;
  padding:10px 12px; margin:8px 0;
}
.ev-title{ font-weight:700; }
.ev-desc{ color:#374151; margin-top:4px; }

</style>
""",
    unsafe_allow_html=True,
)

# =========================
# 2) Sanitizers & Helpers
# =========================
_TAG_RE = re.compile(r"<[^>]+>")
_CTRL_RE = re.compile(r"[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]")
# í•œì(CJK Unified Ideographs) ì œê±° (í‘œì‹œìš©)
_HANJA_RE = re.compile(r"[\u3400-\u4DBF\u4E00-\u9FFF]+")
# Private Use Area í¬í•¨ ë¹„í‘œì‹œ ë¬¸ì(ë¬¸ì œì˜ U+EA01ë„ í¬í•¨) ì œê±°
_PUA_RE = re.compile(r"[\uE000-\uF8FF]")


def scrub_invisible(s: str) -> str:
    if s is None:
        return ""
    s = str(s)
    s = _PUA_RE.sub("", s)
    # í˜¹ì‹œ ë‚¨ì•„ìˆëŠ” ì´ìƒí•œ ì œì–´ë¬¸ì ì œê±°
    s = _CTRL_RE.sub("", s)
    return s


def clean_text(value) -> str:
    """HTML íƒœê·¸/ì œì–´ë¬¸ì/PUA ì œê±°"""
    if value is None:
        return ""
    s = scrub_invisible(unescape(str(value)))
    s = _TAG_RE.sub("", s)
    s = _CTRL_RE.sub("", s)
    return s.strip()


def safe_html(value) -> str:
    return escape(clean_text(value), quote=False).replace("\n", "<br>")


def normalize_whitespace(s: str) -> str:
    s = clean_text(s)
    if not s:
        return ""
    s = s.replace("\r\n", "\n").replace("\r", "\n")
    s = re.sub(r"[ \t]+\n", "\n", s)
    s = re.sub(r"\n{3,}", "\n\n", s)
    return s.strip()


def strip_hanja_for_display(s: str) -> str:
    """í‘œì‹œìš©: í•œì ì œê±° + ì¡ë¬¸ íŒ¨í„´ ì •ë¦¬"""
    s = clean_text(s)
    if not s:
        return ""
    s = _HANJA_RE.sub("", s)
    s = re.sub(r"\|\>+", "", s)
    s = re.sub(r"\s{2,}", " ", s)
    return s.strip()


def truncate_text(s: str, max_chars: int = 2800) -> str:
    s = s or ""
    if len(s) <= max_chars:
        return s
    return s[:max_chars] + "\n...(ë‚´ìš© ì¶•ì†Œë¨)"


def safe_json_dump(obj) -> str:
    try:
        return json.dumps(obj, ensure_ascii=False, default=str)
    except Exception:
        return "{}"


def ensure_doc_shape(doc):
    fallback = {
        "title": "ë¬¸ ì„œ (ìƒì„± ì‹¤íŒ¨)",
        "receiver": "ìˆ˜ì‹ ì ì°¸ì¡°",
        "body_paragraphs": ["ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ ì¸í•´ ë¬¸ì„œ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."],
        "department_head": "í–‰ì •ê¸°ê´€ì¥",
    }
    if not isinstance(doc, dict):
        return fallback

    body = doc.get("body_paragraphs")
    if isinstance(body, str):
        body = [body]
    if not isinstance(body, list) or not body:
        body = fallback["body_paragraphs"]

    return {
        "title": clean_text(doc.get("title") or fallback["title"]),
        "receiver": clean_text(doc.get("receiver") or fallback["receiver"]),
        "body_paragraphs": [clean_text(x) for x in body if clean_text(x)] or fallback["body_paragraphs"],
        "department_head": clean_text(doc.get("department_head") or fallback["department_head"]),
        "_meta": doc.get("_meta", {}),
        "_qa": doc.get("_qa", {}),
    }


def extract_keywords_kor(text: str, max_k: int = 8) -> List[str]:
    """ê°„ì´ í‚¤ì›Œë“œ: LLM ì‹¤íŒ¨ì‹œ fallback"""
    t = clean_text(text)
    if not t:
        return []
    t = re.sub(r"[^ê°€-í£A-Za-z0-9\s]", " ", t)
    words = re.findall(r"[ê°€-í£A-Za-z0-9]{2,14}", t)
    stop = {
        "ê·¸ë¦¬ê³ ", "ê´€ë ¨", "ë¬¸ì˜", "ì‚¬í•­", "ëŒ€í•˜ì—¬", "ëŒ€í•œ", "ì²˜ë¦¬", "ìš”ì²­",
        "ì‘ì„±", "ì•ˆë‚´", "ê²€í† ", "ë¶ˆí¸", "ë¯¼ì›", "ì‹ ì²­", "ë°œê¸‰", "ì œì¶œ",
        "ê°€ëŠ¥", "ì—¬ë¶€", "ì¡°ì¹˜", "í™•ì¸", "í†µë³´", "íšŒì‹ ", "ê²°ê³¼", "ì‚¬ìœ ",
        "í•©ë‹ˆë‹¤", "ìˆìŠµë‹ˆë‹¤", "ì—†ìŠµë‹ˆë‹¤", "ë“±"
    }
    out = []
    for w in words:
        if w in stop:
            continue
        if w.isdigit():
            continue
        if w not in out:
            out.append(w)
        if len(out) >= max_k:
            break
    return out


# =========================
# 3) Metrics
# =========================
def metrics_init():
    if "metrics" not in st.session_state:
        st.session_state["metrics"] = {"calls": {}, "tokens_total": 0}


def metrics_add(model_name: str, tokens_total: Optional[int] = None):
    metrics_init()
    m = st.session_state["metrics"]
    m["calls"][model_name] = m["calls"].get(model_name, 0) + 1
    if tokens_total is not None:
        try:
            m["tokens_total"] += int(tokens_total)
        except Exception:
            pass


metrics_init()


# =========================
# 4) LLM Service (Dual Router)
# =========================
class LLMService:
    """FAST + STRICT"""
    def __init__(self):
        g = st.secrets.get("general", {})
        self.groq_key = g.get("GROQ_API_KEY")
        self.model_fast = g.get("GROQ_MODEL_FAST", "qwen/qwen3-32b")
        self.model_strict = g.get("GROQ_MODEL_STRICT", "llama-3.3-70b-versatile")
        self.client = None

        if Groq and self.groq_key:
            try:
                self.client = Groq(api_key=self.groq_key)
            except Exception:
                self.client = None

    def _chat(self, model: str, messages, temp: float, json_mode: bool):
        if not self.client:
            raise RuntimeError("Groq client not ready (missing key/lib).")

        kwargs = {"model": model, "messages": messages, "temperature": temp}
        if json_mode:
            kwargs["response_format"] = {"type": "json_object"}

        resp = self.client.chat.completions.create(**kwargs)

        tokens_total = None
        try:
            usage = getattr(resp, "usage", None)
            if usage:
                tokens_total = getattr(usage, "total_tokens", None)
        except Exception:
            tokens_total = None

        metrics_add(model, tokens_total=tokens_total)
        return resp.choices[0].message.content or ""

    def _parse_json(self, text: str) -> Dict[str, Any]:
        text = clean_text(text)
        try:
            return json.loads(text)
        except Exception:
            cleaned = re.sub(r"```json|```", "", text).strip()
            m = re.search(r"\{.*\}", cleaned, re.DOTALL)
            if m:
                try:
                    return json.loads(m.group(0))
                except Exception:
                    return {}
            return {}

    def generate_text(self, prompt: str, prefer: str = "fast", temp: float = 0.1) -> str:
        if not self.client:
            return "Groq API Keyê°€ ì—†ê±°ë‚˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¯¸ì„¤ì¹˜"

        model_first = self.model_fast if prefer == "fast" else self.model_strict
        messages = [
            {"role": "system", "content": "You are a Korean public-administration assistant. Be factual, structured, and practical."},
            {"role": "user", "content": prompt},
        ]

        try:
            return self._chat(model_first, messages, temp, json_mode=False)
        except Exception:
            if prefer == "fast":
                try:
                    return self._chat(self.model_strict, messages, temp, json_mode=False)
                except Exception as e2:
                    return f"LLM Error: {e2}"
            return "LLM Error"

    def generate_json(self, prompt: str, prefer: str = "fast", temp: float = 0.1, max_retry: int = 2) -> Dict[str, Any]:
        if not self.client:
            return {}

        sys_json = "Output JSON only. No markdown. No explanation. Follow the schema exactly."
        messages = [
            {"role": "system", "content": sys_json},
            {"role": "user", "content": prompt},
        ]
        model_first = self.model_fast if prefer == "fast" else self.model_strict

        for _ in range(max_retry):
            try:
                txt = self._chat(model_first, messages, temp, json_mode=True)
                js = self._parse_json(txt)
                if js:
                    return js
            except Exception:
                pass

        # escalate
        try:
            txt = self._chat(self.model_strict, messages, temp, json_mode=True)
            js = self._parse_json(txt)
            return js if js else {}
        except Exception:
            return {}


llm = LLMService()


# =========================
# 5) LAW API (DRF) â€” Search + Service (XML)
# =========================
class LawAPIService:
    def __init__(self):
        self.oc = st.secrets.get("law", {}).get("LAW_API_ID")
        self.search_url = "https://www.law.go.kr/DRF/lawSearch.do"
        self.service_url = "https://www.law.go.kr/DRF/lawService.do"
        self.enabled = bool(requests and xmltodict and self.oc)
        self.session = requests.Session() if (requests and self.enabled) else None

    def search_law(self, query: str, display: int = 10) -> List[Dict[str, str]]:
        if not self.enabled or not query:
            return []
        try:
            params = {"OC": self.oc, "target": "law", "type": "XML", "query": query, "display": display, "page": 1}
            r = self.session.get(self.search_url, params=params, timeout=7)
            r.raise_for_status()
            data = xmltodict.parse(r.text)
            laws = data.get("LawSearch", {}).get("law", [])
            if isinstance(laws, dict):
                laws = [laws]
            out = []
            for it in laws:
                if not isinstance(it, dict):
                    continue
                out.append(
                    {
                        "lawNm": clean_text(it.get("ë²•ë ¹ëª…í•œê¸€") or it.get("lawNm") or it.get("ë²•ë ¹ëª…") or ""),
                        "MST": clean_text(it.get("ë²•ë ¹ì¼ë ¨ë²ˆí˜¸") or it.get("MST") or it.get("mst") or ""),
                        "link": clean_text(it.get("ë²•ë ¹ìƒì„¸ë§í¬") or it.get("link") or ""),
                        "promulgation": clean_text(it.get("ê³µí¬ì¼ì") or ""),
                        "amend": clean_text(it.get("ê°œì •ì¼ì") or ""),
                    }
                )
            return [x for x in out if x.get("lawNm") and x.get("MST")]
        except Exception:
            return []

    def _extract_articles(self, law_obj: dict) -> List[dict]:
        articles = law_obj.get("Article", []) or []
        if isinstance(articles, dict):
            articles = [articles]
        return [a for a in articles if isinstance(a, dict)]

    def get_article_by_mst(self, mst: str, article_no: Optional[str] = None) -> Dict[str, Any]:
        if not self.enabled or not mst:
            return {}
        try:
            params = {"OC": self.oc, "target": "law", "type": "XML", "MST": mst}
            r = self.session.get(self.service_url, params=params, timeout=12)
            r.raise_for_status()
            data = xmltodict.parse(r.text)

            law = data.get("Law") or data.get("law") or {}
            law_name = clean_text(law.get("ë²•ë ¹ëª…í•œê¸€") or law.get("LawName") or law.get("ë²•ë ¹ëª…") or "")
            articles = self._extract_articles(law)

            idx = []
            for a in articles[:120]:
                at = clean_text(a.get("ArticleTitle") or "")
                an = clean_text(a.get("@ì¡°ë¬¸ë²ˆí˜¸") or "")
                if at:
                    idx.append(at)
                elif an:
                    idx.append(f"ì œ{an}ì¡°")

            if not article_no:
                if articles:
                    return self._format_article(law_name, mst, articles[0], idx)
                return {"law_name": law_name, "mst": mst, "all_articles_index": idx}

            tgt = re.sub(r"[^0-9]", "", str(article_no))
            if not tgt:
                if articles:
                    return self._format_article(law_name, mst, articles[0], idx)
                return {"law_name": law_name, "mst": mst, "all_articles_index": idx}

            for a in articles:
                an = clean_text(a.get("@ì¡°ë¬¸ë²ˆí˜¸") or "")
                at = clean_text(a.get("ArticleTitle") or "")
                if tgt == re.sub(r"[^0-9]", "", an) or (tgt and f"ì œ{tgt}ì¡°" in at):
                    return self._format_article(law_name, mst, a, idx)

            if articles:
                pack = self._format_article(law_name, mst, articles[0], idx)
                pack["_note"] = f"ìš”ì²­í•œ ì œ{tgt}ì¡°ë¥¼ ì°¾ì§€ ëª»í•´ ì²« ì¡°ë¬¸ìœ¼ë¡œ í‘œì‹œ"
                return pack
            return {"law_name": law_name, "mst": mst, "all_articles_index": idx}

        except Exception:
            return {}

    def _format_article(self, law_name: str, mst: str, art: dict, idx: List[str]) -> Dict[str, Any]:
        at = clean_text(art.get("ArticleTitle") or "")
        an = clean_text(art.get("@ì¡°ë¬¸ë²ˆí˜¸") or "")
        content = clean_text(art.get("ArticleContent") or "")

        paras = art.get("Paragraph", [])
        if isinstance(paras, dict):
            paras = [paras]
        p_lines = []
        for p in paras:
            if not isinstance(p, dict):
                continue
            pc = clean_text(p.get("ParagraphContent") or "")
            if pc:
                p_lines.append(pc)

        text = "\n".join([x for x in [content] + p_lines if x]).strip()
        text = normalize_whitespace(text)
        text_disp = strip_hanja_for_display(text)

        return {
            "law_name": law_name,
            "mst": mst,
            "article_no": re.sub(r"[^0-9]", "", an) or "",
            "article_title": at or (f"ì œ{an}ì¡°" if an else ""),
            "article_text": text_disp,
            "all_articles_index": idx,
        }


law_api = LawAPIService()


# =========================
# 6) NAVER Search (News/Web)
# =========================
class NaverSearchService:
    def __init__(self):
        n = st.secrets.get("naver", {})
        self.cid = n.get("CLIENT_ID")
        self.csec = n.get("CLIENT_SECRET")
        self.enabled = bool(requests and self.cid and self.csec)
        self.session = requests.Session() if (requests and self.enabled) else None

    def search(self, query: str, cat: str = "news", display: int = 5):
        if not self.enabled or not query:
            return []
        try:
            url = f"https://openapi.naver.com/v1/search/{cat}.json"
            headers = {"X-Naver-Client-Id": self.cid, "X-Naver-Client-Secret": self.csec}
            params = {"query": query, "display": display, "sort": "sim", "start": 1}
            r = self.session.get(url, headers=headers, params=params, timeout=7)
            r.raise_for_status()
            return r.json().get("items", []) or []
        except Exception:
            return []


naver = NaverSearchService()


# =========================
# 7) Supabase (optional)
# =========================
class DatabaseService:
    def __init__(self):
        self.client = None
        s = st.secrets.get("supabase", {})
        self.url = s.get("SUPABASE_URL")
        self.key = s.get("SUPABASE_KEY")
        if create_client and self.url and self.key:
            try:
                self.client = create_client(self.url, self.key)
            except Exception:
                self.client = None

    def enabled(self) -> bool:
        return bool(self.client)

    def insert_run(self, row: dict) -> Tuple[bool, str, Optional[str]]:
        if not self.client:
            return False, "DB ë¯¸ì—°ê²°", None
        try:
            safe_row = json.loads(safe_json_dump(row))
            resp = self.client.table("runs").insert(safe_row).execute()
            run_id = None
            data = getattr(resp, "data", None)
            if data and isinstance(data, list) and data:
                run_id = data[0].get("run_id") or data[0].get("id")
            return True, "ì €ì¥ ì„±ê³µ", run_id
        except Exception as e:
            return False, f"ì €ì¥ ì‹¤íŒ¨: {e}", None


db = DatabaseService()


# =========================
# 8) Core: Intake â†’ Candidates â†’ Click-to-Verify â†’ Draft
# =========================
@st.cache_data(ttl=3600, show_spinner=False)
def cached_law_search(q: str) -> List[Dict[str, str]]:
    return law_api.search_law(q, display=10)


@st.cache_data(ttl=3600, show_spinner=False)
def cached_article(mst: str, article_no: str) -> Dict[str, Any]:
    return law_api.get_article_by_mst(mst, article_no=article_no or None)


@st.cache_data(ttl=1800, show_spinner=False)
def cached_naver(q: str, cat: str) -> List[Dict[str, Any]]:
    return naver.search(q, cat=cat, display=7)


def intake_schema(user_input: str) -> Dict[str, Any]:
    kw_fallback = extract_keywords_kor(user_input, max_k=10)
    prompt = f"""
ë‹¤ìŒ ë¯¼ì›/ì—…ë¬´ ì§€ì‹œë¥¼ "í–‰ì •ì‚¬ì‹¤ê´€ê³„" ì¤‘ì‹¬ìœ¼ë¡œ êµ¬ì¡°í™”í•´ë¼.
ë°˜ë“œì‹œ ì•„ë˜ JSON ìŠ¤í‚¤ë§ˆë§Œ ì¶œë ¥(í‚¤ ì¶”ê°€ ê¸ˆì§€).

{{
  "task_type": "ì£¼ê¸°ìœ„ë°˜|ë¬´ë‹¨ë°©ì¹˜|ë¶ˆë²•ì£¼ì •ì°¨|í–‰ì •ì²˜ë¶„|ì •ë³´ê³µê°œ|ê¸°íƒ€",
  "authority_scope": {{
    "my_role": "ì£¼ê¸°ìœ„ë°˜ ë‹¨ì† ë‹´ë‹¹",
    "can_do": ["í˜„ì¥í™•ì¸","ê³„ë„","í†µì§€","ì•ˆë‚´","ì´ê´€"],
    "cannot_do": ["í˜•ì‚¬ìˆ˜ì‚¬","ê°•ì œì§‘í–‰","ì••ìˆ˜ìˆ˜ìƒ‰","êµ¬ê¸ˆ"]
  }},
  "facts": {{
    "who": "ëŒ€ìƒ(ì°¨ëŸ‰/ê±´ì„¤ê¸°ê³„/ì—…ì²´/ê°œì¸ ë“±)",
    "what": "ë¬´ìŠ¨ ì¼ì´ ìˆì—ˆëŠ”ì§€(í•µì‹¬ 1~2ë¬¸ì¥)",
    "where": "ì¥ì†Œ(ëª¨ë¥´ë©´ ë¹ˆë¬¸ìì—´)",
    "when": "ê¸°ê°„/ì¼ì‹œ(ëª¨ë¥´ë©´ ë¹ˆë¬¸ìì—´)",
    "evidence": ["ì‚¬ì§„","ì˜ìƒ","ì§„ìˆ ","ê¸°íƒ€(ì—†ìœ¼ë©´ ë¹ˆë°°ì—´)"]
  }},
  "request": {{
    "user_wants": "ë¯¼ì›ì¸ì´ ì›í•˜ëŠ” ì¡°ì¹˜",
    "constraints": "ê¸°í•œ/ì ˆì°¨/ì´ì˜ì œê¸° ë“±(ì—†ìœ¼ë©´ ë¹ˆë¬¸ìì—´)"
  }},
  "issues": ["ìŸì 1","ìŸì 2"],
  "keywords": ["í‚¤ì›Œë“œ1","í‚¤ì›Œë“œ2","í‚¤ì›Œë“œ3","í‚¤ì›Œë“œ4"]
}}

ì…ë ¥:
"""{user_input}"""

ì£¼ì˜:
- ì…ë ¥ì— ì—†ëŠ” ì‚¬ì‹¤ì€ 'ì¶”ê°€ í™•ì¸ í•„ìš”'ë¡œ ì²˜ë¦¬.
- ì¥ì†Œ/ì‹œê°„ì´ ì—†ìœ¼ë©´ ë¹ˆë¬¸ìì—´.
- keywordsëŠ” 'ì‚¬ì‹¤ ê¸°ë°˜' í•µì‹¬ì–´ë¡œ.
"""
    js = llm.generate_json(prompt, prefer="fast", max_retry=2) or {}
    if not js:
        return {
            "task_type": "ê¸°íƒ€",
            "authority_scope": {"my_role": "ì£¼ê¸°ìœ„ë°˜ ë‹¨ì† ë‹´ë‹¹", "can_do": ["í˜„ì¥í™•ì¸", "ê³„ë„", "í†µì§€", "ì•ˆë‚´", "ì´ê´€"], "cannot_do": ["í˜•ì‚¬ìˆ˜ì‚¬", "ê°•ì œì§‘í–‰", "ì••ìˆ˜ìˆ˜ìƒ‰", "êµ¬ê¸ˆ"]},
            "facts": {"who": "", "what": clean_text(user_input)[:160], "where": "", "when": "", "evidence": []},
            "request": {"user_wants": "", "constraints": ""},
            "issues": [],
            "keywords": kw_fallback[:4],
            "_input_quality": {"score": 60, "missing_fields": ["where", "when"]},
        }

    if not isinstance(js.get("keywords"), list) or not js["keywords"]:
        js["keywords"] = kw_fallback[:4]
    js["keywords"] = [clean_text(x) for x in js["keywords"] if clean_text(x)]
    if not js["keywords"]:
        js["keywords"] = kw_fallback[:4]

    if not isinstance(js.get("issues"), list):
        js["issues"] = []
    js["issues"] = [clean_text(x) for x in js["issues"] if clean_text(x)]

    facts = js.get("facts") if isinstance(js.get("facts"), dict) else {}
    missing = []
    if not clean_text(facts.get("where")):
        missing.append("where")
    if not clean_text(facts.get("when")):
        missing.append("when")
    score = max(40, 100 - 20 * len(missing))
    js["_input_quality"] = {"score": score, "missing_fields": missing}
    return js


def generate_law_candidates(case: Dict[str, Any]) -> List[Dict[str, Any]]:
    task_type = clean_text(case.get("task_type"))
    facts = case.get("facts") if isinstance(case.get("facts"), dict) else {}
    issues = case.get("issues", [])
    keywords = case.get("keywords", [])

    domain_hint = []
    if task_type == "ì£¼ê¸°ìœ„ë°˜":
        domain_hint += ["ê±´ì„¤ê¸°ê³„ê´€ë¦¬ë²•", "ê±´ì„¤ê¸°ê³„ê´€ë¦¬ë²• ì‹œí–‰ë ¹", "ë„ë¡œêµí†µë²•"]
    if task_type == "ë¬´ë‹¨ë°©ì¹˜":
        domain_hint += ["ìë™ì°¨ê´€ë¦¬ë²•", "ë„ë¡œêµí†µë²•"]
    if task_type == "ë¶ˆë²•ì£¼ì •ì°¨":
        domain_hint += ["ë„ë¡œêµí†µë²•", "ì£¼ì°¨ì¥ë²•"]

    prompt = f"""
ë„ˆëŠ” 'ë²•ë ¹ í›„ë³´ ìƒì„±ê¸°'ë‹¤. ë°˜ë“œì‹œ ì•„ë˜ JSONë§Œ ì¶œë ¥.

{{
  "candidates": [
    {{"law_name":"ë²•ë ¹ëª…","article_hint":"ì¡°ë²ˆí˜¸(ìˆ«ìë§Œ, ëª¨ë¥´ë©´ ë¹ˆë¬¸ìì—´)","reason":"ì§§ê²Œ","confidence":0.0}}
  ]
}}

ì…ë ¥(ì‚¬ì‹¤ìš”ì•½):
- task_type: {task_type}
- what: {facts.get("what","")}
- where: {facts.get("where","")}
- when: {facts.get("when","")}
- issues: {issues}
- keywords: {keywords}

ê·œì¹™:
- candidatesëŠ” 4~7ê°œ
- law_nameì€ "ê³µì‹ ë²•ë ¹ëª…" ìš°ì„ 
- article_hintëŠ” ëª¨ë¥´ë©´ ë¹ˆë¬¸ìì—´
- ë‚´ ê¶Œí•œ(ì£¼ê¸°ìœ„ë°˜ ë‹¨ì† ë‹´ë‹¹) ë²”ìœ„ì—ì„œ ë‹¤ë£° ê°€ëŠ¥ì„±ì´ í° ë²•ë ¹ ìš°ì„ 
"""
    js = llm.generate_json(prompt, prefer="fast", max_retry=2) or {}
    cands = js.get("candidates", []) if isinstance(js.get("candidates"), list) else []

    out = [{"law_name": x, "article_hint": "", "reason": "ë„ë©”ì¸ ê·œì¹™ í›„ë³´", "confidence": 0.35} for x in domain_hint]
    for c in cands:
        if not isinstance(c, dict):
            continue
        ln = clean_text(c.get("law_name"))
        if not ln:
            continue
        out.append({
            "law_name": ln,
            "article_hint": clean_text(c.get("article_hint") or ""),
            "reason": clean_text(c.get("reason") or ""),
            "confidence": float(c.get("confidence") or 0.0),
        })

    seen = set()
    uniq = []
    for c in out:
        k = c["law_name"]
        if k in seen:
            continue
        seen.add(k)
        uniq.append(c)
        if len(uniq) >= 10:
            break
    return uniq


def verifier_score(case: Dict[str, Any], article_title: str, article_text: str) -> Dict[str, Any]:
    keywords = case.get("keywords", [])
    issues = case.get("issues", [])
    facts = case.get("facts", {}) if isinstance(case.get("facts"), dict) else {}

    text = (article_title + "\n" + article_text).lower()

    pool = []
    for w in (keywords or [])[:8]:
        w2 = clean_text(w)
        if w2:
            pool.append(w2)
    for w in (issues or [])[:6]:
        w2 = clean_text(w)
        if w2:
            pool.append(w2)
    for w in extract_keywords_kor(clean_text(facts.get("what", "")), max_k=6):
        pool.append(w)
    pool = list(dict.fromkeys(pool))[:12]

    hits = 0
    for w in pool:
        if w and w.lower() in text:
            hits += 1
    relevance = min(40, int((hits / max(1, len(pool))) * 40))

    out_of_scope = ["êµ¬ì†", "ìˆ˜ì‚¬", "ì••ìˆ˜", "ìˆ˜ìƒ‰", "ì²´í¬", "ê¸°ì†Œ", "í˜•ì‚¬", "êµ¬ê¸ˆ"]
    o_hits = sum(1 for w in out_of_scope if w in article_text)
    scope_fit = max(0, 25 - min(25, o_hits * 8))

    match = 10
    if len(article_text) >= 220:
        match += 10
    if any(k.lower() in (article_title.lower() if article_title else "") for k in (keywords or [])[:4] if k):
        match += 5
    article_match = min(25, match)

    risk = 0
    if not article_text or len(article_text) < 80:
        risk += 10
    if "||" in article_text or ">>" in article_text:
        risk += 5
    risk = min(15, risk)

    total = relevance + scope_fit + article_match + (15 - risk)
    verdict = "CONFIRMED" if total >= 78 else ("WEAK" if total >= 55 else "FAIL")

    return {
        "score_total": int(total),
        "verdict": verdict,
        "breakdown": {
            "relevance": int(relevance),
            "scope_fit": int(scope_fit),
            "article_match": int(article_match),
            "risk": int(risk),
        },
        "notes": [f"í‚¤ì›Œë“œ ë§¤ì¹­ {hits}/{max(1,len(pool))}", f"ì›ë¬¸ ê¸¸ì´ {len(article_text)}ì"],
    }


def build_case_query_for_examples(case: Dict[str, Any], law_name: str, article_title: str) -> str:
    kws = case.get("keywords", []) or []
    base = " ".join([k for k in kws[:3] if k])
    title = clean_text(article_title).replace(" ", "")
    return f"{law_name} {title} {base} ê³¼íƒœë£Œ ì²˜ë¶„ ì‚¬ë¡€"


def load_law_pack_from_candidate(case: Dict[str, Any], cand: Dict[str, Any]) -> Dict[str, Any]:
    q = clean_text(cand.get("law_name", ""))
    if not q:
        return {"error": "empty_candidate"}

    results = cached_law_search(q)
    if not results:
        return {"error": "no_search_result", "law_name_query": q}

    chosen = results[0]
    mst = clean_text(chosen.get("MST"))
    law_name = clean_text(chosen.get("lawNm"))
    link = clean_text(chosen.get("link"))
    art_hint = clean_text(cand.get("article_hint") or "")

    pack = cached_article(mst, art_hint)
    pack["law_name"] = law_name or pack.get("law_name", q)
    pack["mst"] = mst
    pack["link"] = link
    pack["article_hint"] = art_hint

    art_title = clean_text(pack.get("article_title", ""))
    art_text = clean_text(pack.get("article_text", ""))

    v = verifier_score(case, art_title, art_text)
    pack["verify"] = v
    pack["score"] = v.get("score_total", 0)
    pack["verdict"] = v.get("verdict", "FAIL")
    return pack


def draft_strategy(case: Dict[str, Any], law_pack: Dict[str, Any], examples_text: str) -> str:
    prefer = "strict" if law_pack.get("verdict") != "CONFIRMED" else "fast"
    prompt = f"""
[ì—…ë¬´ìœ í˜•] {case.get("task_type")}
[ì‚¬ì‹¤(ìš”ì•½)]
- who: {case.get("facts",{}).get("who","")}
- what: {case.get("facts",{}).get("what","")}
- where: {case.get("facts",{}).get("where","")}
- when: {case.get("facts",{}).get("when","")}
[ë¯¼ì› ìš”êµ¬] {case.get("request",{}).get("user_wants","")}
[ìŸì ] {case.get("issues",[])}

[ë²•ì ê·¼ê±°(ì„ íƒ)]
- ë²•ë ¹: {law_pack.get("law_name","")}
- ì¡°ë¬¸: {law_pack.get("article_title","")}
- ì›ë¬¸(ì •ë¦¬): {truncate_text(law_pack.get("article_text","") , 900)}

[ì‚¬ë¡€(ìš”ì•½)]
{truncate_text(examples_text, 900)}

ì•„ë˜ í˜•ì‹(ë§ˆí¬ë‹¤ìš´)ë§Œ ì¶œë ¥:
1) ì²˜ë¦¬ ë°©í–¥(í˜„ì‹¤ì ì¸ í–‰ì • í”„ë¡œì„¸ìŠ¤ ì¤‘ì‹¬, 6~10ì¤„)
2) ì²´í¬ë¦¬ìŠ¤íŠ¸(ë¶ˆë¦¿ 10~14ê°œ, "í™•ì¸/ê¸°ë¡/í†µì§€/ê¸°í•œ" í¬í•¨)
3) ê¶Œí•œë²”ìœ„(í•  ìˆ˜ ìˆëŠ” ê²ƒ/ì—†ëŠ” ê²ƒ ê° 4~6ê°œ)
4) ë¯¼ì›ì¸ ì„¤ëª… í¬ì¸íŠ¸(ì˜¤í•´ ì¤„ì´ëŠ” ë¬¸ì¥ 4~6ê°œ)
"""
    return llm.generate_text(prompt, prefer=prefer, temp=0.1)


def draft_document_json(dept: str, officer: str, case: Dict[str, Any], law_pack: Dict[str, Any], strategy_md: str) -> Dict[str, Any]:
    today_str = datetime.now().strftime("%Y. %m. %d.")
    doc_num = f"í–‰ì •-{datetime.now().strftime('%Y')}-{int(time.time()) % 10000:04d}í˜¸"

    prompt = f"""
ì•„ë˜ ìŠ¤í‚¤ë§ˆë¡œë§Œ JSON ì¶œë ¥(í‚¤ ì¶”ê°€ ê¸ˆì§€):
{{
  "title": "ë¬¸ì„œ ì œëª©",
  "receiver": "ìˆ˜ì‹ ",
  "body_paragraphs": ["ë¬¸ë‹¨1","ë¬¸ë‹¨2","ë¬¸ë‹¨3","ë¬¸ë‹¨4","ë¬¸ë‹¨5"],
  "department_head": "ë°œì‹  ëª…ì˜"
}}

ì‘ì„± ì •ë³´:
- ë¶€ì„œ: {dept}
- ë‹´ë‹¹ì: {officer}
- ì‹œí–‰ì¼: {today_str}
- ë¬¸ì„œë²ˆí˜¸: {doc_num}

ì‚¬ì‹¤ê´€ê³„(í™•ì •ëœ ë²”ìœ„):
- who: {case.get("facts",{}).get("who","")}
- what: {case.get("facts",{}).get("what","")}
- where: {case.get("facts",{}).get("where","")}
- when: {case.get("facts",{}).get("when","")}
- ë¯¼ì›ìš”êµ¬: {case.get("request",{}).get("user_wants","")}
- ì œì•½/ê¸°í•œ: {case.get("request",{}).get("constraints","")}

ë²•ì  ê·¼ê±°(ì›ë¬¸ í™•ë³´ëœ ë²”ìœ„):
- ë²•ë ¹: {law_pack.get("law_name","")}
- ì¡°ë¬¸: {law_pack.get("article_title","")}
- ì›ë¬¸: {truncate_text(law_pack.get("article_text","") , 1400)}

ì²˜ë¦¬ ì „ëµ(ìš”ì•½):
{truncate_text(strategy_md, 900)}

ì‘ì„± ì›ì¹™:
- ë¬¸ì„œ í†¤: ê±´ì¡°/ì •ì¤‘, ì¶”ì¸¡ ê¸ˆì§€
- êµ¬ì¡°: [ê²½ìœ„]â†’[ë²•ì  ê·¼ê±°]â†’[ì¡°ì¹˜/ì•ˆë‚´]â†’[ê¶Œë¦¬êµ¬ì œ/ë¬¸ì˜]
- ê°œì¸ì •ë³´ëŠ” OOOë¡œ ë§ˆìŠ¤í‚¹
- ë²•ë ¹ ê²€ì¦ì´ WEAK/FAILì´ë©´ "ì¶”ê°€ í™•ì¸ í•„ìš”" ë¬¸êµ¬ë¥¼ 'ë²•ì  ê·¼ê±°' ë¬¸ë‹¨ì— í¬í•¨
"""
    js = llm.generate_json(prompt, prefer="strict", max_retry=3) or {}
    out = ensure_doc_shape(js)
    out["_meta"] = {"doc_num": doc_num, "today": today_str, "dept": dept, "officer": officer}
    return out


def qa_guardrails(doc: Dict[str, Any], law_pack: Dict[str, Any]) -> Dict[str, Any]:
    issues = []
    if not doc.get("title"):
        issues.append("title_missing")
    if not doc.get("receiver"):
        issues.append("receiver_missing")
    if not isinstance(doc.get("body_paragraphs"), list) or len(doc.get("body_paragraphs")) < 3:
        issues.append("body_weak")

    forbidden = ["í™•ì‹¤íˆ", "ë°˜ë“œì‹œ", "100%", "ë¬´ì¡°ê±´"]
    body = "\n".join(doc.get("body_paragraphs", []))
    if any(x in body for x in forbidden):
        issues.append("overconfident_language")

    if law_pack.get("verdict") in ("WEAK", "FAIL") and ("ê·¼ê±°" in body and "ì¶”ê°€ í™•ì¸ í•„ìš”" not in body):
        issues.append("law_confidence_low_missing_note")

    doc["_qa"] = {"issues": issues}
    return doc


# =========================
# 9) Click-to-Verify UI pieces
# =========================
def render_a4(doc: Dict[str, Any], meta: Dict[str, str]):
    body_html = "".join([f"<p style='margin:0 0 14px 0; text-indent: 12px;'>{safe_html(p)}</p>" for p in doc.get("body_paragraphs", [])])
    html = f"""
<div class="paper-sheet" id="printable-area">
  <div class="stamp">ì§ì¸ìƒëµ</div>
  <div class="doc-header">{safe_html(doc.get('title',''))}</div>
  <div class="doc-info">
    <span><b>ë¬¸ì„œë²ˆí˜¸</b>: {safe_html(meta.get('doc_num',''))}</span>
    <span><b>ì‹œí–‰ì¼ì</b>: {safe_html(meta.get('today',''))}</span>
    <span><b>ìˆ˜ì‹ </b>: {safe_html(doc.get('receiver',''))}</span>
  </div>
  <div class="doc-body">{body_html}</div>
  <div class="doc-footer">{safe_html(doc.get('department_head',''))}</div>
  <div class="small-muted" style="margin-top:18px;">
    ë‹´ë‹¹: {safe_html(meta.get('officer',''))} Â· {safe_html(meta.get('dept',''))}
  </div>
</div>
"""
    components.html(html, height=920, scrolling=True)
    st.download_button(
        "ğŸ“¥ ê³µë¬¸ HTMLë¡œ ë‚´ë³´ë‚´ê¸°",
        data=html,
        file_name=f"ê³µë¬¸_{meta.get('doc_num','')}.html",
        mime="text/html",
        use_container_width=True,
    )


def render_law_pack(law_pack: Dict[str, Any]):
    if not law_pack or law_pack.get("error"):
        st.warning(f"ë²•ë ¹ ì›ë¬¸ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {law_pack.get('error')}")
        return

    law_name = law_pack.get("law_name", "")
    article_title = law_pack.get("article_title", "")
    verdict = law_pack.get("verdict", "")
    score = law_pack.get("score", 0)
    link = law_pack.get("link", "")

    st.markdown(f"**ì„ íƒ ë²•ë ¹:** {law_name}  \n**ì¡°ë¬¸:** {article_title}  \n**ê²€ì¦:** {verdict} / score={score}")
    if link:
        st.markdown(f"- ìƒì„¸ ë§í¬: {link}")

    txt = normalize_whitespace(law_pack.get("article_text", "") or "")
    txt = strip_hanja_for_display(txt)
    if not txt:
        st.warning("ì¡°ë¬¸ ì›ë¬¸ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤(ë‹¤ë¥¸ í›„ë³´ë¥¼ ì„ íƒí•˜ì„¸ìš”).")
        return

    st.markdown("### ì¡°ë¬¸ ì›ë¬¸(ì •ë¦¬ë³¸)")
    st.code(txt, language="text")

    v = law_pack.get("verify") or {}
    if v:
        st.markdown("### Verifier")
        st.json(v)


def render_examples(case: Dict[str, Any], law_pack: Dict[str, Any]):
    if not (naver.enabled and case and law_pack and law_pack.get("law_name")):
        st.info("ë„¤ì´ë²„ APIê°€ ì—†ê±°ë‚˜(ë˜ëŠ”) ì¼€ì´ìŠ¤/ë²•ë ¹ ì„ íƒì´ ì—†ì–´ ì‚¬ë¡€ ê²€ìƒ‰ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    q = build_case_query_for_examples(case, law_pack.get("law_name",""), law_pack.get("article_title",""))

    st.caption(f"ì‚¬ë¡€ ê²€ìƒ‰ ì¿¼ë¦¬: {q}")

    news = cached_naver(q, "news")
    webk = cached_naver(q, "webkr")

    def _item_card(it: Dict[str, Any]):
        title = clean_text(it.get("title","")) or "(ì œëª©ì—†ìŒ)"
        desc = clean_text(it.get("description","")) or ""
        link = clean_text(it.get("link","")) or ""
        if link:
            st.markdown(
                f"<div class='ev-card'><div class='ev-title'><a href='{link}' target='_blank'>{escape(title)}</a></div><div class='ev-desc'>{escape(desc)}</div></div>",
                unsafe_allow_html=True
            )
        else:
            st.markdown(
                f"<div class='ev-card'><div class='ev-title'>{escape(title)}</div><div class='ev-desc'>{escape(desc)}</div></div>",
                unsafe_allow_html=True
            )

    st.markdown("### ğŸ“° ë‰´ìŠ¤ ì‚¬ë¡€")
    if not news:
        st.caption("ë‰´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
    for it in news[:7]:
        _item_card(it)

    st.markdown("### ğŸŒ ì›¹ ë¬¸ì„œ/íŒë¡€/í•´ì„¤(ê²€ìƒ‰)")
    if not webk:
        st.caption("ì›¹ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
    for it in webk[:7]:
        _item_card(it)

    lines = []
    for it in (news[:5] + webk[:5]):
        t = clean_text(it.get("title","")) or ""
        d = clean_text(it.get("description","")) or ""
        if t:
            lines.append(f"- {t}: {d}")
    st.session_state["examples_text"] = "\n".join(lines).strip()


# =========================
# 10) Performance Lab (ëˆˆìœ¼ë¡œ í™•ì¸)
# =========================
@dataclass
class BenchResult:
    name: str
    n: int
    unit: str
    mean: float
    p50: float
    p95: float
    min_v: float
    max_v: float
    mem_kb: float


def _percentile(xs: List[float], p: float) -> float:
    if not xs:
        return 0.0
    xs = sorted(xs)
    k = int(round((len(xs) - 1) * p))
    k = max(0, min(k, len(xs) - 1))
    return xs[k]


def bench_fn(name: str, fn, n: int = 200, warmup: int = 20, measure_mem: bool = True) -> BenchResult:
    for _ in range(max(0, warmup)):
        fn()

    mem_peak_kb = 0.0
    if measure_mem:
        tracemalloc.start()

    times = []
    for _ in range(n):
        t0 = perf_counter_ns()
        fn()
        t1 = perf_counter_ns()
        times.append((t1 - t0) / 1000.0)  # Î¼s

    if measure_mem:
        cur, peak = tracemalloc.get_traced_memory()
        tracemalloc.stop()
        mem_peak_kb = peak / 1024.0

    mean = statistics.mean(times)
    p50 = _percentile(times, 0.50)
    p95 = _percentile(times, 0.95)
    return BenchResult(name=name, n=n, unit="Î¼s", mean=mean, p50=p50, p95=p95, min_v=min(times), max_v=max(times), mem_kb=mem_peak_kb)


def render_bench_table(results: List[BenchResult], title: str):
    if not results:
        st.info("ì¸¡ì • ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    if not pd:
        st.warning("pandas ë¯¸ì„¤ì¹˜ë¼ í‘œ/ì°¨íŠ¸ í‘œì‹œê°€ ì œí•œë©ë‹ˆë‹¤.")
        for r in results:
            st.write(r)
        return

    df = pd.DataFrame([{
        "name": r.name,
        "n": r.n,
        "mean(Î¼s)": round(r.mean, 2),
        "p50(Î¼s)": round(r.p50, 2),
        "p95(Î¼s)": round(r.p95, 2),
        "min(Î¼s)": round(r.min_v, 2),
        "max(Î¼s)": round(r.max_v, 2),
        "peak_mem(KB)": round(r.mem_kb, 1),
    } for r in results]).sort_values(["p95(Î¼s)", "mean(Î¼s)"], ascending=[False, False])

    st.subheader(title)
    st.dataframe(df, use_container_width=True, hide_index=True)
    st.caption("p95 ê¸°ì¤€(í° ê°’ì¼ìˆ˜ë¡ ëŠë¦¼)")
    chart_df = df[["name", "p95(Î¼s)", "mean(Î¼s)"]].set_index("name")
    st.bar_chart(chart_df)


def render_performance_lab():
    st.markdown("## ğŸ§ª ì„±ëŠ¥ ì‹¤í—˜ì‹¤(Performance Lab)")
    st.caption("ë²„íŠ¼ í´ë¦­ â†’ ì•±ì˜ í•µì‹¬ ì—°ì‚°ì„ ì‹¤ì œë¡œ ì¬ì„œ p50/p95/ë©”ëª¨ë¦¬ í”¼í¬ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.")

    n = st.slider("ë°˜ë³µ íšŸìˆ˜(n)", min_value=50, max_value=2000, value=300, step=50)
    measure_mem = st.checkbox("ë©”ëª¨ë¦¬ í”¼í¬(tracemalloc) ì¸¡ì •", value=True)

    sample_text = st.text_area(
        "ìƒ˜í”Œ í…ìŠ¤íŠ¸(ì •ê·œí™”/í•œìì œê±°/HTML ì•ˆì „í™” ì¸¡ì •ìš©)",
        value="ê±´ì„¤ê¸°ê³„ ì£¼ê¸°ìœ„ë°˜ ê´€ë ¨ ë¯¼ì›. í˜„ì¥ í™•ì¸ ê²°ê³¼ ì´ë™í•¨. ë¯¼ì›ì¸ì€ ìƒì‹œ ë‹¨ì† ë° ê³¼íƒœë£Œ ë¶€ê³¼ ìš”êµ¬. ì œ33ì¡° ì ìš© ì—¬ë¶€ ê²€í† .",
        height=110
    )

    pack = st.session_state.get("selected_law_pack") or {}
    law_text = (pack.get("article_text") or "")[:3000]

    colA, colB = st.columns(2)
    with colA:
        if st.button("âš¡ ë¡œì»¬ ì—°ì‚° ë²¤ì¹˜", use_container_width=True):
            res = []
            res.append(bench_fn("clean_text()", lambda: clean_text(sample_text), n=n, measure_mem=measure_mem))
            res.append(bench_fn("normalize_whitespace()", lambda: normalize_whitespace(sample_text), n=n, measure_mem=measure_mem))
            res.append(bench_fn("strip_hanja_for_display()", lambda: strip_hanja_for_display(sample_text), n=n, measure_mem=measure_mem))
            res.append(bench_fn("safe_html()", lambda: safe_html(sample_text), n=n, measure_mem=measure_mem))
            if law_text:
                case = st.session_state.get("case_struct") or {"keywords": [], "issues": [], "facts": {"what": ""}}
                res.append(bench_fn("verifier_score()", lambda: verifier_score(case, pack.get("article_title",""), law_text), n=max(50, n//3), measure_mem=measure_mem))
            render_bench_table(res, "Local Ops")

    with colB:
        if st.button("ğŸ“¦ JSON ì§ë ¬í™” ë²¤ì¹˜", use_container_width=True):
            obj = {
                "text": sample_text,
                "kws": extract_keywords_kor(sample_text, 10),
                "pack": pack,
                "ts": datetime.now().isoformat(),
                "nums": list(range(200)),
                "nested": [{"a": i, "b": {"x": i*2, "y": str(i)}} for i in range(50)],
            }
            res = []
            res.append(bench_fn("json.dumps()", lambda: json.dumps(obj, ensure_ascii=False, default=str), n=n, measure_mem=measure_mem))
            if orjson:
                res.append(bench_fn("orjson.dumps()", lambda: orjson.dumps(obj), n=n, measure_mem=measure_mem))
            else:
                st.info("orjson ë¯¸ì„¤ì¹˜(ì„ íƒ): pip install orjson")
            if msgspec:
                enc = msgspec.json.Encoder()
                res.append(bench_fn("msgspec.encode()", lambda: enc.encode(obj), n=n, measure_mem=measure_mem))
            else:
                st.info("msgspec ë¯¸ì„¤ì¹˜(ì„ íƒ): pip install msgspec")
            render_bench_table(res, "Serialization")

    st.markdown("---")
    st.markdown("### ğŸŒ I/O ë²¤ì¹˜(ì„ íƒ)")
    st.caption("ë„¤íŠ¸ì›Œí¬ ì˜í–¥ì´ í¬ë¯€ë¡œ 'ìµœì í™” ì „í›„ ë¹„êµ' ìš©ë„ì…ë‹ˆë‹¤.")
    io_n = st.slider("I/O ë°˜ë³µ íšŸìˆ˜", min_value=1, max_value=30, value=5, step=1)

    if st.button("ğŸŒ DRF/ë„¤ì´ë²„ í˜¸ì¶œ ë²¤ì¹˜", use_container_width=True):
        res = []
        case = st.session_state.get("case_struct") or {}
        cand = st.session_state.get("law_candidates", [])[:1]
        if cand:
            c = cand[0]
            res.append(bench_fn("load_law_pack_from_candidate()", lambda: load_law_pack_from_candidate(case, c), n=io_n, warmup=0, measure_mem=False))
        else:
            st.warning("ë¨¼ì € ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ í›„ í›„ë³´ê°€ ìƒê¸°ë©´ ì¸¡ì •í•˜ì„¸ìš”.")

        if naver.enabled:
            q = " ".join(extract_keywords_kor(sample_text, 3)) + " ê³¼íƒœë£Œ ì²˜ë¶„ ì‚¬ë¡€"
            res.append(bench_fn("naver.search(news)", lambda: cached_naver(q, "news"), n=io_n, warmup=0, measure_mem=False))
            res.append(bench_fn("naver.search(webkr)", lambda: cached_naver(q, "webkr"), n=io_n, warmup=0, measure_mem=False))
        else:
            st.info("ë„¤ì´ë²„ API ë¯¸ì„¤ì •ì´ë¼ ì œì™¸ë¨.")

        render_bench_table(res, "Network / I/O (msê¸‰ì´ ì •ìƒ)")


# =========================
# 11) Workflow Controller
# =========================
def run_workflow(user_input: str, dept: str, officer: str):
    log_area = st.empty()
    logs = []

    def add_log(msg: str, style: str = "sys"):
        logs.append(f"<div class='agent-log log-{style}'>{safe_html(msg)}</div>")
        log_area.markdown("".join(logs), unsafe_allow_html=True)
        time.sleep(0.02)

    add_log("ğŸ§¾ [INTAKE] ì‚¬ì‹¤ê´€ê³„ êµ¬ì¡°í™”(FAST)", "sys")
    case = intake_schema(user_input)
    st.session_state["case_struct"] = case
    add_log(f"âœ… [INTAKE] ì™„ë£Œ (quality={case.get('_input_quality',{}).get('score','?')})", "sys")

    add_log("ğŸ§© [LAW-CAND] ë²•ë ¹ í›„ë³´ ìƒì„±(FAST)", "legal")
    candidates = generate_law_candidates(case)
    st.session_state["law_candidates"] = candidates
    add_log("ğŸ“Œ í›„ë³´ ìƒì„± ì™„ë£Œ â€” ì˜¤ë¥¸ìª½ 'ë²•ì  ê·¼ê±°(í´ë¦­)' íƒ­ì—ì„œ í›„ë³´ë¥¼ ëˆŒëŸ¬ ì›ë¬¸/ì‚¬ë¡€ í™•ì¸", "legal")

    if candidates:
        add_log("ğŸ“š [LAW] 1ë²ˆ í›„ë³´ ì›ë¬¸ ë¡œë“œ(ìºì‹œ/ì„¸ì…˜ ì ìš©)", "legal")
        pack = load_law_pack_from_candidate(case, candidates[0])
        st.session_state["selected_candidate_idx"] = 0
        st.session_state["selected_law_pack"] = pack

    log_area.empty()
    return case


def build_strategy_and_doc(dept: str, officer: str):
    case = st.session_state.get("case_struct") or {}
    law_pack = st.session_state.get("selected_law_pack") or {}
    examples_text = st.session_state.get("examples_text") or ""

    strategy = draft_strategy(case, law_pack, examples_text)
    st.session_state["strategy_md"] = strategy

    doc = draft_document_json(dept, officer, case, law_pack, strategy)
    doc = qa_guardrails(doc, law_pack)
    st.session_state["doc_json"] = ensure_doc_shape(doc)


# =========================
# 12) Main UI
# =========================
def main():
    st.session_state.setdefault("dept", "OOì‹œì²­ OOê³¼")
    st.session_state.setdefault("officer", "ê¹€ì£¼ë¬´ê´€")
    st.session_state.setdefault("case_struct", None)
    st.session_state.setdefault("law_candidates", [])
    st.session_state.setdefault("selected_candidate_idx", 0)
    st.session_state.setdefault("selected_law_pack", {})
    st.session_state.setdefault("examples_text", "")
    st.session_state.setdefault("strategy_md", "")
    st.session_state.setdefault("doc_json", None)

    col_l, col_r = st.columns([1, 1.25], gap="large")

    with col_l:
        st.title("AI í–‰ì •ê´€ Pro")
        st.caption("v8.1 â€” Click-to-Verify(ì›ë¬¸+ì‚¬ë¡€) + A4 ê³µë¬¸ + ì„±ëŠ¥ì‹¤í—˜ì‹¤")
        st.markdown("---")

        with st.expander("ğŸ§© ë¶€ì„œ/ë‹´ë‹¹ì ì„¤ì •", expanded=False):
            st.text_input("ë¶€ì„œëª…", key="dept")
            st.text_input("ë‹´ë‹¹ì", key="officer")
            st.caption("â€» Groq/Law/Naver í‚¤ëŠ” secrets.tomlì— ì„¤ì •í•˜ì„¸ìš”.")

        user_input = st.text_area(
            "ì—…ë¬´ ì§€ì‹œ ì‚¬í•­(ë¯¼ì› ìƒí™© í¬í•¨)",
            height=220,
            placeholder="ì˜ˆ: ê±´ì„¤ê¸°ê³„ê°€ ì°¨ê³ ì§€ ì™¸ ì¥ê¸°ê°„ ì£¼ì°¨(ì£¼ê¸°ìœ„ë°˜) ì‹ ê³ ê°€ ë“¤ì–´ì™”ê³ , í˜„ì¥ í™•ì¸í–ˆë”ë‹ˆ ì´ë™í•œ ìƒíƒœ. ë¯¼ì›ì¸ì€ ìƒì‹œ ë‹¨ì†ì„ ìš”êµ¬. ë‹´ë‹¹ìê°€ í•  ìˆ˜ ìˆëŠ” ì¡°ì¹˜ì™€ ë‹µë³€ ê³µë¬¸ ì‘ì„±.",
        )

        c1, c2 = st.columns(2)
        with c1:
            if st.button("ğŸš€ 1) ë¶„ì„ ì‹œì‘(í›„ë³´ ìƒì„±)", type="primary", use_container_width=True):
                if not user_input.strip():
                    st.warning("ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”.")
                else:
                    with st.spinner("êµ¬ì¡°í™” â†’ ë²•ë ¹ í›„ë³´ ìƒì„± ì¤‘..."):
                        run_workflow(user_input.strip(), st.session_state["dept"], st.session_state["officer"])
                        st.success("í›„ë³´ ìƒì„± ì™„ë£Œ! ì˜¤ë¥¸ìª½ íƒ­ì—ì„œ í›„ë³´ í´ë¦­ â†’ ì›ë¬¸/ì‚¬ë¡€ í™•ì¸í•˜ì„¸ìš”.")

        with c2:
            if st.button("âœï¸ 2) ê³µë¬¸ ìƒì„±(ì›ë¬¸/ì‚¬ë¡€ í™•ì¸ í›„)", use_container_width=True):
                if not st.session_state.get("case_struct"):
                    st.warning("ë¨¼ì € 1) ë¶„ì„ ì‹œì‘ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
                else:
                    with st.spinner("ì „ëµ/ê³µë¬¸ ìƒì„± ì¤‘..."):
                        build_strategy_and_doc(st.session_state["dept"], st.session_state["officer"])
                        st.success("ê³µë¬¸ ìƒì„± ì™„ë£Œ!")

        st.markdown("---")
        st.subheader("ğŸ“Š ì„¸ì…˜ ì‚¬ìš©ëŸ‰")
        m = st.session_state.get("metrics", {})
        calls = m.get("calls", {})
        tokens_total = m.get("tokens_total", 0)
        if calls:
            for k, v in sorted(calls.items(), key=lambda x: (-x[1], x[0])):
                st.write(f"- **{k}**: {v}íšŒ")
            st.caption(f"ì´ í† í°(ê°€ëŠ¥í•œ ê²½ìš°): {tokens_total}")
        else:
            st.info("ëŒ€ê¸° ì¤‘...")

        st.markdown("<div class='small-muted'>í•µì‹¬ ì‚¬ìš©ë²•: í›„ë³´ í´ë¦­ â†’ ì›ë¬¸+ì‚¬ë¡€ í™•ì¸ â†’ ê·¸ ë‹¤ìŒ ê³µë¬¸ ìƒì„±.</div>", unsafe_allow_html=True)

    with col_r:
        tabs = st.tabs(["ğŸ“„ ê³µë¬¸(A4)", "âš–ï¸ ë²•ì  ê·¼ê±°(í´ë¦­)", "ğŸ§¾ ì‚¬ë¡€(í´ë¦­)", "ğŸ§  ì „ëµ/êµ¬ì¡°í™”", "ğŸ§ª ì„±ëŠ¥ì‹¤í—˜ì‹¤"])

        with tabs[0]:
            doc = st.session_state.get("doc_json")
            if not doc:
                st.markdown(
                    """
<div style='text-align:center; padding:120px 20px; color:#9ca3af; border:2px dashed #e5e7eb; border-radius:14px; background:#fff;'>
  <h3 style='margin-bottom:8px;'>ğŸ“„ A4 ë¯¸ë¦¬ë³´ê¸°</h3>
  <p>1) ë¶„ì„ ì‹œì‘ â†’ 2) í›„ë³´ í´ë¦­ìœ¼ë¡œ ê·¼ê±° í™•ì¸ â†’ 3) ê³µë¬¸ ìƒì„±</p>
</div>
""",
                    unsafe_allow_html=True,
                )
            else:
                meta = doc.get("_meta") or {}
                render_a4(doc, meta)

        with tabs[1]:
            case = st.session_state.get("case_struct") or {}
            cands = st.session_state.get("law_candidates") or []
            st.markdown("## âš–ï¸ ë²•ì  ê·¼ê±° â€” í›„ë³´ë¥¼ í´ë¦­í•´ì„œ ì›ë¬¸ì„ í™•ì¸")
            if not cands:
                st.info("ì™¼ìª½ì—ì„œ 1) ë¶„ì„ ì‹œì‘ì„ ì‹¤í–‰í•˜ë©´ í›„ë³´ê°€ ìƒì„±ë©ë‹ˆë‹¤.")
            else:
                for i, c in enumerate(cands[:10]):
                    law_name = clean_text(c.get("law_name","")) or "(ë²•ë ¹ëª… ì—†ìŒ)"
                    hint = clean_text(c.get("article_hint","")) or "-"
                    conf = float(c.get("confidence", 0.0) or 0.0)
                    label = f"{i+1}. {law_name}"
                    badge = f"<span class='badge'>hint:{hint} Â· conf:{conf:.2f}</span>"
                    cols = st.columns([0.80, 0.20])
                    with cols[0]:
                        st.markdown(f"<div class='card'><div class='card-title'>{escape(label)} {badge}</div><div class='card-sub'>{escape(clean_text(c.get('reason','')))}</div></div>", unsafe_allow_html=True)
                    with cols[1]:
                        if st.button("ì›ë¬¸ë³´ê¸°", key=f"pick_{i}", use_container_width=True):
                            pack = load_law_pack_from_candidate(case, c)
                            st.session_state["selected_candidate_idx"] = i
                            st.session_state["selected_law_pack"] = pack
                            st.success(f"ì„ íƒ: {pack.get('law_name','')} / {pack.get('article_title','')}")
                st.markdown("---")
                st.markdown("### ğŸ“Œ ì„ íƒëœ ë²•ë ¹ ì›ë¬¸")
                render_law_pack(st.session_state.get("selected_law_pack") or {})

        with tabs[2]:
            st.markdown("## ğŸ§¾ ì‚¬ë¡€ â€” 'ì„ íƒëœ ë²•ë ¹' ê¸°ì¤€ìœ¼ë¡œ ì‚¬ë¡€ë¥¼ í´ë¦­í•´ í™•ì¸")
            case = st.session_state.get("case_struct") or {}
            pack = st.session_state.get("selected_law_pack") or {}
            if not case or not pack:
                st.info("ë¨¼ì € 'ë²•ì  ê·¼ê±°(í´ë¦­)'ì—ì„œ í›„ë³´ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
            else:
                render_examples(case, pack)

        with tabs[3]:
            st.markdown("## ğŸ§  ì „ëµ/êµ¬ì¡°í™”")
            case = st.session_state.get("case_struct")
            if not case:
                st.info("ì•„ì§ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.markdown("### 1) êµ¬ì¡°í™”ëœ ì‚¬ì‹¤ê´€ê³„")
                st.json(case)

                st.markdown("### 2) ì„ íƒ ë²•ë ¹(ìš”ì•½)")
                pack = st.session_state.get("selected_law_pack") or {}
                if pack:
                    st.write(f"- {pack.get('law_name','')} / {pack.get('article_title','')} / {pack.get('verdict','')} (score={pack.get('score',0)})")
                else:
                    st.caption("ì„ íƒëœ ë²•ë ¹ ì—†ìŒ")

                st.markdown("### 3) ì²˜ë¦¬ ì „ëµ(ê³µë¬¸ ìƒì„± í›„ í‘œì‹œ)")
                strat = st.session_state.get("strategy_md") or ""
                if strat:
                    st.markdown(strat)
                else:
                    st.caption("ê³µë¬¸ ìƒì„±(2)ì„ ëˆ„ë¥´ë©´ ì „ëµì´ ìƒì„±ë©ë‹ˆë‹¤.")

                doc = st.session_state.get("doc_json")
                if doc:
                    st.markdown("### 4) ê³µë¬¸ JSON(ë””ë²„ê·¸)")
                    st.json(doc)

        with tabs[4]:
            render_performance_lab()


if __name__ == "__main__":
    main()
