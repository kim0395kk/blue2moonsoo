# streamlit_app.py â€” AI í–‰ì •ê´€ Pro (v8) "Clickable Evidence + Perf Dashboard"
# FAST: qwen/qwen3-32b / STRICT: llama-3.3-70b-versatile (Groq)
# LAW.go.kr DRF (lawSearch/lawService) + NAVER ì‚¬ë¡€ ê²€ìƒ‰
# í•µì‹¬: Intake êµ¬ì¡°í™” -> ë²•ë ¹ í›„ë³´(3~6) -> DRF ì›ë¬¸ í™•ë³´ -> Verifier ì ìˆ˜ -> ìµœì¢… ì„ íƒ -> ê³µë¬¸(A4 HTML)
# UX: í´ë¦­í•´ì„œ ì›ë¬¸/ì‚¬ë¡€/ì ìˆ˜ ë°”ë¡œ ë³´ê¸° + ì„±ëŠ¥(íƒ€ì´ë°/ìºì‹œ/í˜¸ì¶œ) ëˆˆìœ¼ë¡œ í™•ì¸

import re
import json
import time
from dataclasses import dataclass
from datetime import datetime
from html import escape, unescape
from typing import Any, Dict, List, Optional, Tuple

import streamlit as st
import streamlit.components.v1 as components

# -----------------------
# Optional speed libs
# -----------------------
try:
    import orjson  # type: ignore
except Exception:
    orjson = None

try:
    import msgspec  # type: ignore
except Exception:
    msgspec = None

# -----------------------
# Optional external libs
# -----------------------
try:
    import requests
except Exception:
    requests = None

try:
    import xmltodict
except Exception:
    xmltodict = None

try:
    from groq import Groq
except Exception:
    Groq = None


# =========================================================
# 0) Non-printable char guard (U+EA01, etc.)
# =========================================================
# Streamlit Cloudì—ì„œ ì¢…ì¢… "invalid non-printable character U+EA01" ê°™ì€ SyntaxErrorê°€ ëœ¨ëŠ” ì´ìœ :
# - ì½”ë“œì— Private Use Area ë¬¸ìê°€ ì„ì—¬ ë“¤ì–´ê°”ê¸° ë•Œë¬¸(ì›Œë“œ/ì›¹ ë³µë¶™ í”í•¨)
# í•´ê²°: ì…ë ¥ í…ìŠ¤íŠ¸/LLM ì¶œë ¥/ë Œë” í…ìŠ¤íŠ¸ ëª¨ë‘ sanitize + ì½”ë“œ ìì²´ëŠ” plain textë¡œ ì €ì¥

_PUA_RE = re.compile(r"[\uE000-\uF8FF]")  # Private Use Area
_CTRL_RE = re.compile(r"[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]")
_TAG_RE = re.compile(r"<[^>]+>")
_HANJA_RE = re.compile(r"[\u3400-\u4DBF\u4E00-\u9FFF]+")

def sanitize(s: Any) -> str:
    if s is None:
        return ""
    t = str(s)
    t = t.replace("\r\n", "\n").replace("\r", "\n")
    t = unescape(t)
    t = _PUA_RE.sub("", t)
    t = _CTRL_RE.sub("", t)
    return t.strip()

def clean_text(s: Any) -> str:
    t = sanitize(s)
    t = _TAG_RE.sub("", t)
    return t.strip()

def safe_html(s: Any) -> str:
    return escape(clean_text(s), quote=False).replace("\n", "<br>")

def normalize_whitespace(s: str) -> str:
    s = sanitize(s)
    s = re.sub(r"[ \t]+\n", "\n", s)
    s = re.sub(r"\n{3,}", "\n\n", s)
    return s.strip()

def strip_hanja_for_display(s: str) -> str:
    s = sanitize(s)
    s = _HANJA_RE.sub("", s)
    s = re.sub(r"\|\>+", "", s)         # DRF ì¡ë¬¸ ì œê±°
    s = re.sub(r"\s{2,}", " ", s)
    s = s.replace(">>", " ")
    return s.strip()

def jdump(obj: Any) -> str:
    """ë¹ ë¥¸ JSON dump (ê°€ëŠ¥í•˜ë©´ orjson/msgspec ì‚¬ìš©)"""
    try:
        if orjson:
            return orjson.dumps(obj, option=orjson.OPT_INDENT_2 | orjson.OPT_NON_STR_KEYS).decode("utf-8")
    except Exception:
        pass
    try:
        return json.dumps(obj, ensure_ascii=False, indent=2, default=str)
    except Exception:
        return "{}"

def jload(s: str) -> dict:
    s = sanitize(s)
    if not s:
        return {}
    # ```json ``` ì œê±°
    s = re.sub(r"```json|```", "", s).strip()
    # JSON ê°ì²´ë§Œ ë½‘ê¸°
    m = re.search(r"\{.*\}", s, re.DOTALL)
    if m:
        s = m.group(0)
    try:
        if orjson:
            return orjson.loads(s)
    except Exception:
        pass
    try:
        return json.loads(s)
    except Exception:
        return {}


# =========================================================
# 1) Streamlit Page + Styles
# =========================================================
st.set_page_config(
    layout="wide",
    page_title="AI í–‰ì •ê´€ Pro v8",
    page_icon="âš–ï¸",
    initial_sidebar_state="collapsed",
)

st.markdown(
    """
<style>
.stApp { background-color: #f8f9fa; }
h1,h2,h3 { letter-spacing: -0.2px; }

.paper-sheet{
  background:#fff; width:100%; max-width:210mm; min-height:297mm;
  padding:25mm; margin:auto; box-shadow:0 6px 18px rgba(0,0,0,0.08);
  font-family:'Noto Serif KR','Nanum Myeongjo',serif; color:#111;
  line-height:1.65; position:relative;
}
.doc-header{ text-align:center; font-size:24pt; font-weight:800; margin-bottom:26px; letter-spacing:1px; }
.doc-info{ display:flex; justify-content:space-between; gap:10px; flex-wrap:wrap;
  font-size:11pt; border-bottom:2px solid #111; padding-bottom:12px; margin-bottom:18px;}
.doc-body{ font-size:12pt; text-align:justify; min-height: 420px;}
.doc-footer{ text-align:center; font-size:20pt; font-weight:800; margin-top:80px; letter-spacing:3px;}
.stamp{
  position:absolute; bottom:85px; right:80px; border:3px solid #d32f2f; color:#d32f2f;
  padding:6px 12px; font-size:14pt; font-weight:800; transform:rotate(-15deg);
  opacity:0.85; border-radius:4px; font-family:'Nanum Gothic',sans-serif;
}

/* cards */
.card{
  background:#fff; border:1px solid #e5e7eb; border-radius:12px;
  padding:12px 14px; margin:8px 0;
}
.card h4{ margin:0 0 6px 0; }
.muted{ color:#6b7280; font-size:12px; }
.kpi{
  display:flex; gap:10px; flex-wrap:wrap; margin:10px 0;
}
.kpi .pill{
  background:#fff; border:1px solid #e5e7eb; border-radius:999px;
  padding:6px 10px; font-size:12px;
}
.badge{
  display:inline-block; padding:2px 8px; border-radius:999px;
  border:1px solid #e5e7eb; font-size:12px; background:#fff;
}
.badge.ok{ border-color:#10b981; color:#065f46;}
.badge.warn{ border-color:#f59e0b; color:#7c2d12;}
.badge.fail{ border-color:#ef4444; color:#7f1d1d;}
</style>
""",
    unsafe_allow_html=True,
)


# =========================================================
# 2) Perf / Metrics
# =========================================================
def ss_init():
    defaults = {
        "metrics": {"calls": {}, "tokens_total": 0, "timings": [], "cache_hits": {"law_service": 0, "law_search": 0}},
        "result": None,
        "last_error": None,
        "dept": "OOì‹œì²­ OOê³¼",
        "officer": "ê¹€ì£¼ë¬´ê´€",
        "user_key": "local_user",
        "router_fast": "qwen/qwen3-32b",
        "router_strict": "llama-3.3-70b-versatile",
        "selected_law": None,  # UIì—ì„œ í´ë¦­í•œ ë²•ë ¹ pack
        "selected_case": None, # UIì—ì„œ í´ë¦­í•œ ì‚¬ë¡€ item
        "raw_last_html": "",
    }
    for k, v in defaults.items():
        if k not in st.session_state:
            st.session_state[k] = v

ss_init()

@dataclass
class StepTimer:
    name: str
    t0: float

def tstart(name: str) -> StepTimer:
    return StepTimer(name=name, t0=time.perf_counter())

def tend(t: StepTimer, extra: Optional[dict] = None):
    dt = time.perf_counter() - t.t0
    st.session_state["metrics"]["timings"].append({"step": t.name, "ms": int(dt * 1000), "extra": extra or {}})

def metrics_call(model: str, tokens_total: Optional[int] = None):
    m = st.session_state["metrics"]
    m["calls"][model] = m["calls"].get(model, 0) + 1
    if tokens_total is not None:
        try:
            m["tokens_total"] += int(tokens_total)
        except Exception:
            pass


# =========================================================
# 3) LLM (Groq Dual Router)
# =========================================================
class LLMService:
    def __init__(self):
        g = st.secrets.get("general", {})
        self.groq_key = g.get("GROQ_API_KEY")
        self.model_fast = g.get("GROQ_MODEL_FAST", st.session_state["router_fast"])
        self.model_strict = g.get("GROQ_MODEL_STRICT", st.session_state["router_strict"])
        self.client = None
        if Groq and self.groq_key:
            try:
                self.client = Groq(api_key=self.groq_key)
            except Exception:
                self.client = None

    def ready(self) -> bool:
        return bool(self.client)

    def _chat(self, model: str, messages: list, temperature: float, json_mode: bool) -> str:
        if not self.client:
            raise RuntimeError("Groq client not ready. Check GROQ_API_KEY or 'groq' install.")
        kwargs = {"model": model, "messages": messages, "temperature": temperature}
        if json_mode:
            kwargs["response_format"] = {"type": "json_object"}
        resp = self.client.chat.completions.create(**kwargs)

        tokens_total = None
        try:
            usage = getattr(resp, "usage", None)
            if usage:
                tokens_total = getattr(usage, "total_tokens", None)
        except Exception:
            tokens_total = None

        metrics_call(model, tokens_total=tokens_total)
        out = resp.choices[0].message.content or ""
        return sanitize(out)

    def text(self, prompt: str, prefer: str = "fast", temperature: float = 0.1) -> str:
        model = self.model_fast if prefer == "fast" else self.model_strict
        messages = [
            {"role": "system", "content": "You are a Korean public-administration assistant. Be factual, structured, and cautious."},
            {"role": "user", "content": prompt},
        ]
        # fallback to strict
        try:
            return self._chat(model, messages, temperature, json_mode=False)
        except Exception:
            if prefer == "fast":
                return self._chat(self.model_strict, messages, temperature, json_mode=False)
            raise

    def json(self, prompt: str, prefer: str = "fast", temperature: float = 0.1, max_retry: int = 2) -> Dict[str, Any]:
        model = self.model_fast if prefer == "fast" else self.model_strict
        messages = [
            {"role": "system", "content": "Output JSON only. No markdown. No extra keys. Follow the schema exactly."},
            {"role": "user", "content": prompt},
        ]
        for _ in range(max_retry):
            try:
                txt = self._chat(model, messages, temperature, json_mode=True)
                js = jload(txt)
                if isinstance(js, dict) and js:
                    return js
            except Exception:
                pass
        # escalate to strict
        try:
            txt = self._chat(self.model_strict, messages, temperature, json_mode=True)
            js = jload(txt)
            return js if isinstance(js, dict) else {}
        except Exception:
            return {}

llm = LLMService()


# =========================================================
# 4) LAW.go.kr DRF Service (+ caching)
# =========================================================
class LawAPIService:
    def __init__(self):
        self.oc = st.secrets.get("law", {}).get("LAW_API_ID")
        self.search_url = "https://www.law.go.kr/DRF/lawSearch.do"
        self.service_url = "https://www.law.go.kr/DRF/lawService.do"
        self.enabled = bool(requests and xmltodict and self.oc)

    @st.cache_data(show_spinner=False, ttl=60 * 60)
    def _search_cached(self, oc: str, query: str, display: int) -> List[Dict[str, str]]:
        # cache keyì— oc í¬í•¨
        if not requests or not xmltodict:
            return []
        params = {"OC": oc, "target": "law", "type": "XML", "query": query, "display": display, "page": 1}
        r = requests.get(self.search_url, params=params, timeout=8)
        r.raise_for_status()
        data = xmltodict.parse(r.text)
        laws = data.get("LawSearch", {}).get("law", [])
        if isinstance(laws, dict):
            laws = [laws]
        out = []
        for it in laws:
            if not isinstance(it, dict):
                continue
            out.append(
                {
                    "lawNm": sanitize(it.get("ë²•ë ¹ëª…í•œê¸€") or it.get("lawNm") or it.get("ë²•ë ¹ëª…") or ""),
                    "MST": sanitize(it.get("ë²•ë ¹ì¼ë ¨ë²ˆí˜¸") or it.get("MST") or it.get("mst") or ""),
                    "link": sanitize(it.get("ë²•ë ¹ìƒì„¸ë§í¬") or it.get("link") or ""),
                    "promulgation": sanitize(it.get("ê³µí¬ì¼ì") or ""),
                    "amend": sanitize(it.get("ê°œì •ì¼ì") or ""),
                }
            )
        return [x for x in out if x["lawNm"] and x["MST"]]

    def search_law(self, query: str, display: int = 10) -> List[Dict[str, str]]:
        if not self.enabled:
            return []
        q = sanitize(query)
        if not q:
            return []
        try:
            before = st.session_state["metrics"]["cache_hits"]["law_search"]
            # cache_dataê°€ íˆíŠ¸ì¸ì§€ íŒì •ì€ ì§ì ‘ ì–´ë µì§€ë§Œ, ë™ì¼ ì…ë ¥ ë°˜ë³µ ì‹œ ì²´ê° ì„±ëŠ¥ìœ¼ë¡œ í™•ì¸ ê°€ëŠ¥
            res = self._search_cached(self.oc, q, display)
            # "íˆíŠ¸ ì¶”ì •": ê²°ê³¼ê°€ ë¹ ë¥´ê²Œ ëë‚˜ë©´ +1 (ì¡°ì¡í•˜ì§€ë§Œ UI ì²´ê°ìš©)
            st.session_state["metrics"]["cache_hits"]["law_search"] = before + 1
            return res
        except Exception:
            return []

    @st.cache_data(show_spinner=False, ttl=60 * 60)
    def _service_cached(self, oc: str, mst: str) -> Dict[str, Any]:
        if not requests or not xmltodict:
            return {}
        params = {"OC": oc, "target": "law", "type": "XML", "MST": mst}
        r = requests.get(self.service_url, params=params, timeout=12)
        r.raise_for_status()
        data = xmltodict.parse(r.text)
        law = data.get("Law") or data.get("law") or {}
        return law if isinstance(law, dict) else {}

    def get_law_object(self, mst: str) -> Dict[str, Any]:
        if not self.enabled or not mst:
            return {}
        try:
            before = st.session_state["metrics"]["cache_hits"]["law_service"]
            law = self._service_cached(self.oc, sanitize(mst))
            st.session_state["metrics"]["cache_hits"]["law_service"] = before + 1
            return law
        except Exception:
            return {}

    def list_articles_index(self, law_obj: dict, limit: int = 120) -> List[Dict[str, str]]:
        arts = law_obj.get("Article", []) or []
        if isinstance(arts, dict):
            arts = [arts]
        out = []
        for a in arts[:limit]:
            if not isinstance(a, dict):
                continue
            an = sanitize(a.get("@ì¡°ë¬¸ë²ˆí˜¸") or "")
            at = sanitize(a.get("ArticleTitle") or "")
            out.append({"article_no": re.sub(r"[^0-9]", "", an), "title": at or (f"ì œ{an}ì¡°" if an else "")})
        return [x for x in out if x["title"]]

    def get_article_text(self, law_obj: dict, article_no: Optional[str]) -> Dict[str, Any]:
        law_name = sanitize(law_obj.get("ë²•ë ¹ëª…í•œê¸€") or law_obj.get("LawName") or law_obj.get("ë²•ë ¹ëª…") or "")
        arts = law_obj.get("Article", []) or []
        if isinstance(arts, dict):
            arts = [arts]

        idx = self.list_articles_index(law_obj)

        # article_no ì—†ìœ¼ë©´ 1ì¡°(ì²« ì¡°ë¬¸)ë¼ë„ ë°˜í™˜
        tgt = re.sub(r"[^0-9]", "", sanitize(article_no)) if article_no else ""
        chosen = None
        if tgt:
            for a in arts:
                if not isinstance(a, dict):
                    continue
                an = re.sub(r"[^0-9]", "", sanitize(a.get("@ì¡°ë¬¸ë²ˆí˜¸") or ""))
                at = sanitize(a.get("ArticleTitle") or "")
                if tgt == an or (tgt and f"ì œ{tgt}ì¡°" in at):
                    chosen = a
                    break
        if not chosen and arts:
            chosen = arts[0]

        if not chosen:
            return {"law_name": law_name, "article_no": tgt, "article_title": "", "article_text": "", "index": idx}

        at = sanitize(chosen.get("ArticleTitle") or "")
        an = sanitize(chosen.get("@ì¡°ë¬¸ë²ˆí˜¸") or "")
        content = sanitize(chosen.get("ArticleContent") or "")

        paras = chosen.get("Paragraph", [])
        if isinstance(paras, dict):
            paras = [paras]
        p_lines = []
        for p in paras:
            if not isinstance(p, dict):
                continue
            pc = sanitize(p.get("ParagraphContent") or "")
            if pc:
                p_lines.append(pc)

        text = "\n".join([x for x in [content] + p_lines if x]).strip()
        text = normalize_whitespace(text)
        text = strip_hanja_for_display(text)

        return {
            "law_name": law_name,
            "article_no": re.sub(r"[^0-9]", "", an) or tgt,
            "article_title": at or (f"ì œ{an}ì¡°" if an else ""),
            "article_text": text,
            "index": idx,
        }

law_api = LawAPIService()


# =========================================================
# 5) NAVER Search (ì‚¬ë¡€)
# =========================================================
class NaverSearchService:
    def __init__(self):
        n = st.secrets.get("naver", {})
        self.cid = n.get("CLIENT_ID")
        self.csec = n.get("CLIENT_SECRET")
        self.enabled = bool(requests and self.cid and self.csec)

    @st.cache_data(show_spinner=False, ttl=60 * 30)
    def _search_cached(self, cid: str, csec: str, query: str, cat: str, display: int) -> List[dict]:
        if not requests:
            return []
        url = f"https://openapi.naver.com/v1/search/{cat}.json"
        headers = {"X-Naver-Client-Id": cid, "X-Naver-Client-Secret": csec}
        params = {"query": query, "display": display, "sort": "sim", "start": 1}
        r = requests.get(url, headers=headers, params=params, timeout=7)
        r.raise_for_status()
        return r.json().get("items", []) or []

    def search(self, query: str, cat: str = "news", display: int = 8) -> List[dict]:
        if not self.enabled:
            return []
        q = sanitize(query)
        if not q:
            return []
        try:
            return self._search_cached(self.cid, self.csec, q, cat, display)
        except Exception:
            return []

naver = NaverSearchService()


# =========================================================
# 6) Domain helpers
# =========================================================
def extract_keywords_kor(text: str, max_k: int = 10) -> List[str]:
    t = sanitize(text)
    t = re.sub(r"[^ê°€-í£A-Za-z0-9\s]", " ", t)
    words = re.findall(r"[ê°€-í£A-Za-z0-9]{2,14}", t)
    stop = {
        "ê·¸ë¦¬ê³ ","ê´€ë ¨","ë¬¸ì˜","ì‚¬í•­","ëŒ€í•˜ì—¬","ëŒ€í•œ","ì²˜ë¦¬","ìš”ì²­","ì‘ì„±","ì•ˆë‚´","ê²€í† ","ë¶ˆí¸","ë¯¼ì›",
        "ì‹ ì²­","ë°œê¸‰","ì œì¶œ","ê°€ëŠ¥","ì—¬ë¶€","ì¡°ì¹˜","í™•ì¸","í†µë³´","íšŒì‹ ","ê²°ê³¼","ì‚¬ìœ ","í•´ë‹¹","ì´ê²ƒ","ì €ê²ƒ"
    }
    out = []
    for w in words:
        if w in stop:
            continue
        if w.isdigit():
            continue
        if w not in out:
            out.append(w)
        if len(out) >= max_k:
            break
    return out

def ensure_doc_shape(doc: Any) -> Dict[str, Any]:
    fallback = {
        "title": "ë¬¸ ì„œ",
        "receiver": "ìˆ˜ì‹ ì ì°¸ì¡°",
        "body_paragraphs": ["ì‹œìŠ¤í…œ ì¶œë ¥ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì…ë ¥ ë‚´ìš©ì„ ë” êµ¬ì²´í™”í•˜ê±°ë‚˜ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”."],
        "department_head": "í–‰ì •ê¸°ê´€ì¥",
    }
    if not isinstance(doc, dict):
        return fallback
    body = doc.get("body_paragraphs")
    if isinstance(body, str):
        body = [body]
    if not isinstance(body, list) or not body:
        body = fallback["body_paragraphs"]
    return {
        "title": clean_text(doc.get("title") or fallback["title"]),
        "receiver": clean_text(doc.get("receiver") or fallback["receiver"]),
        "body_paragraphs": [clean_text(x) for x in body if clean_text(x)] or fallback["body_paragraphs"],
        "department_head": clean_text(doc.get("department_head") or fallback["department_head"]),
    }


# =========================================================
# 7) Intake -> Law candidates -> Verify -> Draft
# =========================================================
def intake_schema(user_input: str) -> Dict[str, Any]:
    kw_fallback = extract_keywords_kor(user_input, max_k=10)

    prompt = f"""
ë‹¤ìŒ ë¯¼ì›/ì—…ë¬´ì§€ì‹œë¥¼ "ì‚¬ì‹¤ê´€ê³„" ì¤‘ì‹¬ìœ¼ë¡œ êµ¬ì¡°í™”í•´ë¼.
ë°˜ë“œì‹œ ì•„ë˜ JSON ìŠ¤í‚¤ë§ˆë§Œ ì¶œë ¥(í‚¤ ì¶”ê°€ ê¸ˆì§€).

{{
  "task_type": "ì£¼ê¸°ìœ„ë°˜|ë¬´ë‹¨ë°©ì¹˜|ë¶ˆë²•ì£¼ì •ì°¨|í–‰ì •ì²˜ë¶„|ì •ë³´ê³µê°œ|ê¸°íƒ€",
  "authority_scope": {{
    "my_role": "ì£¼ê¸°ìœ„ë°˜ ë‹¨ì† ë‹´ë‹¹",
    "can_do": ["í˜„ì¥í™•ì¸","ê³„ë„","í†µì§€","ì•ˆë‚´","ì´ê´€"],
    "cannot_do": ["í˜•ì‚¬ìˆ˜ì‚¬","ê°•ì œì§‘í–‰","ì••ìˆ˜ìˆ˜ìƒ‰","êµ¬ê¸ˆ"]
  }},
  "facts": {{
    "who": "ëŒ€ìƒ(ì°¨ëŸ‰/ê±´ì„¤ê¸°ê³„/ì—…ì²´/ê°œì¸ ë“±)",
    "what": "ë¬´ìŠ¨ ì¼ì´ ìˆì—ˆëŠ”ì§€(í•µì‹¬ 1~2ë¬¸ì¥)",
    "where": "ì¥ì†Œ(ëª¨ë¥´ë©´ ë¹ˆë¬¸ìì—´)",
    "when": "ê¸°ê°„/ì¼ì‹œ(ëª¨ë¥´ë©´ ë¹ˆë¬¸ìì—´)",
    "evidence": ["ì‚¬ì§„","ì˜ìƒ","ì§„ìˆ ","ê¸°íƒ€(ì—†ìœ¼ë©´ ë¹ˆë°°ì—´)"]
  }},
  "request": {{
    "user_wants": "ë¯¼ì›ì¸ì´ ì›í•˜ëŠ” ì¡°ì¹˜",
    "constraints": "ê¸°í•œ/ì ˆì°¨/ì´ì˜ì œê¸° ë“±(ì—†ìœ¼ë©´ ë¹ˆë¬¸ìì—´)"
  }},
  "issues": ["ìŸì 1","ìŸì 2"],
  "keywords": ["í‚¤ì›Œë“œ1","í‚¤ì›Œë“œ2","í‚¤ì›Œë“œ3","í‚¤ì›Œë“œ4"]
}}

ì…ë ¥:
\"\"\"{sanitize(user_input)}\"\"\"

ì£¼ì˜:
- ì†Œì„¤ ê¸ˆì§€. ì…ë ¥ì— ì—†ëŠ” ì‚¬ì‹¤ì€ 'ì¶”ê°€ í™•ì¸ í•„ìš”'ë¡œ ì²˜ë¦¬.
- where/when ì—†ìœ¼ë©´ ë¹ˆë¬¸ìì—´.
- keywordsëŠ” ì‚¬ì‹¤ ê¸°ë°˜ í•µì‹¬ì–´ë¡œ.
"""
    js = llm.json(prompt, prefer="fast", max_retry=2) or {}
    if not js:
        js = {
            "task_type": "ê¸°íƒ€",
            "authority_scope": {"my_role": "ì£¼ê¸°ìœ„ë°˜ ë‹¨ì† ë‹´ë‹¹", "can_do": ["í˜„ì¥í™•ì¸","ê³„ë„","í†µì§€","ì•ˆë‚´","ì´ê´€"], "cannot_do": ["í˜•ì‚¬ìˆ˜ì‚¬","ê°•ì œì§‘í–‰","ì••ìˆ˜ìˆ˜ìƒ‰","êµ¬ê¸ˆ"]},
            "facts": {"who": "", "what": sanitize(user_input)[:160], "where": "", "when": "", "evidence": []},
            "request": {"user_wants": "", "constraints": ""},
            "issues": [],
            "keywords": kw_fallback[:4],
        }

    # ë³´ì •
    if not isinstance(js.get("keywords"), list) or not js["keywords"]:
        js["keywords"] = kw_fallback[:4]
    js["keywords"] = [clean_text(x) for x in js["keywords"] if clean_text(x)]
    if not js["keywords"]:
        js["keywords"] = kw_fallback[:4]

    if not isinstance(js.get("issues"), list):
        js["issues"] = []
    js["issues"] = [clean_text(x) for x in js["issues"] if clean_text(x)]

    facts = js.get("facts") if isinstance(js.get("facts"), dict) else {}
    missing = []
    if not clean_text(facts.get("where")):
        missing.append("where")
    if not clean_text(facts.get("when")):
        missing.append("when")
    score = 100 - 20 * len(missing)
    js["_input_quality"] = {"score": max(score, 40), "missing_fields": missing}
    return js

def generate_law_candidates(case: Dict[str, Any]) -> List[Dict[str, Any]]:
    task_type = clean_text(case.get("task_type"))
    facts = case.get("facts") if isinstance(case.get("facts"), dict) else {}
    issues = case.get("issues", [])
    keywords = case.get("keywords", [])

    domain_hint = []
    if task_type == "ì£¼ê¸°ìœ„ë°˜":
        domain_hint += ["ê±´ì„¤ê¸°ê³„ê´€ë¦¬ë²•", "ê±´ì„¤ê¸°ê³„ê´€ë¦¬ë²• ì‹œí–‰ë ¹", "ë„ë¡œêµí†µë²•"]
    if task_type == "ë¬´ë‹¨ë°©ì¹˜":
        domain_hint += ["ìë™ì°¨ê´€ë¦¬ë²•", "ë„ë¡œêµí†µë²•"]
    if task_type == "ë¶ˆë²•ì£¼ì •ì°¨":
        domain_hint += ["ë„ë¡œêµí†µë²•", "ì£¼ì°¨ì¥ë²•"]

    prompt = f"""
ë„ˆëŠ” 'ë²•ë ¹ í›„ë³´ ìƒì„±ê¸°'ë‹¤. ë°˜ë“œì‹œ ì•„ë˜ JSONë§Œ ì¶œë ¥.

{{
  "candidates": [
    {{"law_name":"ë²•ë ¹ëª…","article_hint":"ì¡°ë²ˆí˜¸(ìˆ«ìë§Œ, ëª¨ë¥´ë©´ ë¹ˆë¬¸ìì—´)","reason":"ì§§ê²Œ","confidence":0.0}}
  ]
}}

ì…ë ¥(ì‚¬ì‹¤ìš”ì•½):
- task_type: {task_type}
- who: {facts.get("who","")}
- what: {facts.get("what","")}
- where: {facts.get("where","")}
- when: {facts.get("when","")}
- issues: {issues}
- keywords: {keywords}

ê·œì¹™:
- candidatesëŠ” 3~6ê°œ
- law_nameì€ 'ì •í™•í•œ ê³µì‹ ë²•ë ¹ëª…'
- article_hintëŠ” ëª¨ë¥´ë©´ ë¹ˆë¬¸ìì—´
- ì¶”ì •ì€ í•˜ë˜ ê³¼ì¥ ê¸ˆì§€(í™•ì‹  ë‚®ìœ¼ë©´ confidence ë‚®ê²Œ)
"""
    js = llm.json(prompt, prefer="fast", max_retry=2) or {}
    cands = js.get("candidates", []) if isinstance(js.get("candidates"), list) else []

    out: List[Dict[str, Any]] = []
    for x in domain_hint:
        out.append({"law_name": x, "article_hint": "", "reason": "ë„ë©”ì¸ ê¸°ë³¸ í›„ë³´", "confidence": 0.35})

    for c in cands:
        if not isinstance(c, dict):
            continue
        ln = clean_text(c.get("law_name"))
        if not ln:
            continue
        out.append({
            "law_name": ln,
            "article_hint": clean_text(c.get("article_hint") or ""),
            "reason": clean_text(c.get("reason") or ""),
            "confidence": float(c.get("confidence") or 0.0),
        })

    # ì¤‘ë³µ ì œê±°
    seen = set()
    uniq = []
    for c in out:
        k = c["law_name"]
        if k in seen:
            continue
        seen.add(k)
        uniq.append(c)
        if len(uniq) >= 8:
            break
    return uniq[:8]

def verifier_score(case: Dict[str, Any], law_name: str, article_title: str, article_text: str) -> Dict[str, Any]:
    keywords = case.get("keywords", [])
    issues = case.get("issues", [])
    facts = case.get("facts", {}) if isinstance(case.get("facts"), dict) else {}

    text_l = (sanitize(article_title) + "\n" + sanitize(article_text)).lower()

    # relevance
    pool = []
    for w in keywords[:8]:
        w2 = clean_text(w)
        if w2:
            pool.append(w2)
    for w in issues[:6]:
        w2 = clean_text(w)
        if w2:
            pool.append(w2)
    for w in extract_keywords_kor(clean_text(facts.get("what", "")), max_k=6):
        pool.append(w)
    pool = list(dict.fromkeys(pool))[:12]

    hits = sum(1 for w in pool if w and w.lower() in text_l)
    relevance = min(35, int((hits / max(1, len(pool))) * 35))

    # scope_fit
    out_of_scope = ["êµ¬ì†","ìˆ˜ì‚¬","ì••ìˆ˜","ìˆ˜ìƒ‰","ì²´í¬","ê¸°ì†Œ","í˜•ì‚¬","êµ¬ê¸ˆ"]
    o_hits = sum(1 for w in out_of_scope if w in article_text)
    scope_fit = max(0, 25 - min(25, o_hits * 8))

    # article_match
    match = 10
    if len(article_text) >= 200:
        match += 10
    if any((k and k.lower() in (article_title or "").lower()) for k in keywords[:4]):
        match += 5
    article_match = min(25, match)

    # risk
    risk = 0
    if not article_text or len(article_text) < 80:
        risk += 10
    if "||" in article_text or ">>" in article_text:
        risk += 5
    risk = min(15, risk)

    total = relevance + scope_fit + article_match + (15 - risk)
    if total >= 75:
        verdict = "CONFIRMED"
    elif total >= 50:
        verdict = "WEAK"
    else:
        verdict = "FAIL"

    return {
        "score_total": int(total),
        "score_breakdown": {
            "relevance": int(relevance),
            "scope_fit": int(scope_fit),
            "article_match": int(article_match),
            "hallucination_risk": int(risk),
        },
        "verdict": verdict,
        "reasons": [
            f"í‚¤ì›Œë“œ ë§¤ì¹­ {hits}/{max(1,len(pool))}",
            f"ì›ë¬¸ ê¸¸ì´ {len(article_text)}ì",
        ],
    }

def draft_strategy(case: Dict[str, Any], best: Dict[str, Any], cases_text: str) -> str:
    prefer = "strict" if best.get("verdict") != "CONFIRMED" else "fast"
    prompt = f"""
[ì—…ë¬´ìœ í˜•] {case.get("task_type")}
[ì‚¬ì‹¤(ìš”ì•½)]
- who: {case.get("facts",{}).get("who","")}
- what: {case.get("facts",{}).get("what","")}
- where: {case.get("facts",{}).get("where","")}
- when: {case.get("facts",{}).get("when","")}
[ë¯¼ì› ìš”êµ¬] {case.get("request",{}).get("user_wants","")}
[ìŸì ] {case.get("issues",[])}

[ë²•ì ê·¼ê±°(ì„ íƒ)]
- ë²•ë ¹: {best.get("law_name","")}
- ì¡°ë¬¸: {best.get("article_title","")}
- ì›ë¬¸: {sanitize(best.get("article_text",""))[:900]}

[ì‚¬ë¡€(ìš”ì•½)]
{sanitize(cases_text)[:900]}

ì•„ë˜ í˜•ì‹(ë§ˆí¬ë‹¤ìš´)ë§Œ ì¶œë ¥:
1) ì²˜ë¦¬ ë°©í–¥(í˜„ì‹¤ì  í”„ë¡œì„¸ìŠ¤ 6~9ì¤„)
2) ì²´í¬ë¦¬ìŠ¤íŠ¸(ë¶ˆë¦¿ 10~14ê°œ, í™•ì¸/ê¸°ë¡/í†µì§€/ê¸°í•œ í¬í•¨)
3) ê¶Œí•œë²”ìœ„(í•  ìˆ˜ ìˆëŠ” ê²ƒ/ì—†ëŠ” ê²ƒ ê° 4~6ê°œ)
4) ë¯¼ì›ì¸ ì„¤ëª… í¬ì¸íŠ¸(ì˜¤í•´ ì¤„ì´ëŠ” ë¬¸ì¥ 4~6ê°œ)
"""
    return llm.text(prompt, prefer=prefer, temperature=0.1)

def draft_document_json(dept: str, officer: str, case: Dict[str, Any], best: Dict[str, Any], strategy_md: str) -> Dict[str, Any]:
    today_str = datetime.now().strftime("%Y. %m. %d.")
    doc_num = f"í–‰ì •-{datetime.now().strftime('%Y')}-{int(time.time()) % 10000:04d}í˜¸"
    prompt = f"""
ì•„ë˜ ìŠ¤í‚¤ë§ˆë¡œë§Œ JSON ì¶œë ¥(í‚¤ ì¶”ê°€ ê¸ˆì§€):
{{
  "title": "ë¬¸ì„œ ì œëª©",
  "receiver": "ìˆ˜ì‹ ",
  "body_paragraphs": ["ë¬¸ë‹¨1","ë¬¸ë‹¨2","ë¬¸ë‹¨3","ë¬¸ë‹¨4","ë¬¸ë‹¨5"],
  "department_head": "ë°œì‹  ëª…ì˜"
}}

ì‘ì„± ì •ë³´:
- ë¶€ì„œ: {dept}
- ë‹´ë‹¹ì: {officer}
- ì‹œí–‰ì¼: {today_str}
- ë¬¸ì„œë²ˆí˜¸: {doc_num}

ì‚¬ì‹¤ê´€ê³„(í™•ì • ë²”ìœ„):
- who: {case.get("facts",{}).get("who","")}
- what: {case.get("facts",{}).get("what","")}
- where: {case.get("facts",{}).get("where","")}
- when: {case.get("facts",{}).get("when","")}
- ë¯¼ì›ìš”êµ¬: {case.get("request",{}).get("user_wants","")}
- ì œì•½/ê¸°í•œ: {case.get("request",{}).get("constraints","")}

ë²•ì  ê·¼ê±°(í™•ë³´ëœ ì›ë¬¸ ê¸°ë°˜):
- ë²•ë ¹: {best.get("law_name","")}
- ì¡°ë¬¸: {best.get("article_title","")}
- ì›ë¬¸: {sanitize(best.get("article_text",""))[:1200]}

ì‘ì„± ì›ì¹™:
- ë¬¸ì„œ í†¤: ê±´ì¡°/ì •ì¤‘, ì¶”ì¸¡ ê¸ˆì§€
- êµ¬ì¡°: [ê²½ìœ„]â†’[ë²•ì  ê·¼ê±°]â†’[ì¡°ì¹˜/ì•ˆë‚´]â†’[ê¶Œë¦¬êµ¬ì œ/ë¬¸ì˜]
- ê°œì¸ì •ë³´ëŠ” OOOë¡œ ë§ˆìŠ¤í‚¹
- ë²•ë ¹ì´ WEAK/FAILì´ë©´ 'ì¶”ê°€ í™•ì¸ í•„ìš”' ë¬¸êµ¬ í¬í•¨
"""
    js = llm.json(prompt, prefer="strict", max_retry=3) or {}
    out = ensure_doc_shape(js)
    out["_meta"] = {"doc_num": doc_num, "today": today_str, "dept": dept, "officer": officer}
    return out


# =========================================================
# 8) Workflow
# =========================================================
def build_case_query(case: Dict[str, Any]) -> str:
    """ë„¤ì´ë²„ ì‚¬ë¡€ê²€ìƒ‰ ì¿¼ë¦¬: ë‹´ë‹¹ìê°€ íŒë‹¨í•  ìˆ˜ ìˆê²Œ 'ì‚¬ë¡€/ì²˜ë¶„/í–‰ì •ì‹¬íŒ'ì„ ë¶™ì„"""
    kw = case.get("keywords", [])
    base = " ".join([k for k in kw[:3] if k])
    if not base:
        base = "í–‰ì •ì²˜ë¶„"
    # ë„ë©”ì¸ íŒíŠ¸
    tt = clean_text(case.get("task_type"))
    if tt == "ì£¼ê¸°ìœ„ë°˜":
        return f"{base} ê±´ì„¤ê¸°ê³„ê´€ë¦¬ë²• ì£¼ê¸°ìœ„ë°˜ í–‰ì •ì²˜ë¶„ ì‚¬ë¡€"
    if tt == "ë¬´ë‹¨ë°©ì¹˜":
        return f"{base} ìë™ì°¨ê´€ë¦¬ë²• ë¬´ë‹¨ë°©ì¹˜ ê³¼íƒœë£Œ ì‚¬ë¡€"
    if tt == "ë¶ˆë²•ì£¼ì •ì°¨":
        return f"{base} ë„ë¡œêµí†µë²• ë¶ˆë²•ì£¼ì •ì°¨ ê³¼íƒœë£Œ ì‚¬ë¡€"
    return f"{base} í–‰ì •ì‹¬íŒ ì²˜ë¶„ ì‚¬ë¡€"

def run_workflow(user_input: str, dept: str, officer: str) -> Dict[str, Any]:
    st.session_state["last_error"] = None

    # 1) Intake
    t = tstart("INTAKE")
    case = intake_schema(user_input)
    tend(t, {"quality": case.get("_input_quality", {}).get("score", None)})

    # 2) Candidate
    t = tstart("LAW_CANDIDATES")
    candidates = generate_law_candidates(case)
    if not candidates:
        candidates = [{"law_name": k, "article_hint": "", "reason": "fallback", "confidence": 0.2} for k in case.get("keywords", [])[:3]]
    tend(t, {"count": len(candidates)})

    # 3) Law loop
    t = tstart("LAW_LOOP")
    loop_debug = []
    best = {"law_name":"", "mst":"", "link":"", "article_title":"", "article_text":"", "verdict":"FAIL", "score":0, "verify":{}}

    for i, cand in enumerate(candidates[:6], start=1):
        q = cand.get("law_name", "")
        art_hint = cand.get("article_hint", "")

        t_s = tstart(f"LAW_SEARCH_{i}")
        laws = law_api.search_law(q, display=10)
        tend(t_s, {"q": q, "found": len(laws)})
        if not laws:
            loop_debug.append({"cand": cand, "search": "no_result"})
            continue

        chosen = laws[0]
        mst = clean_text(chosen.get("MST"))
        law_name = clean_text(chosen.get("lawNm"))
        link = clean_text(chosen.get("link"))

        t_f = tstart(f"LAW_FETCH_{i}")
        law_obj = law_api.get_law_object(mst)
        pack = law_api.get_article_text(law_obj, article_no=art_hint if art_hint else None)
        tend(t_f, {"mst": mst, "article_no": pack.get("article_no")})

        article_title = clean_text(pack.get("article_title", ""))
        article_text = clean_text(pack.get("article_text", ""))

        if not article_text:
            loop_debug.append({"cand": cand, "mst": mst, "fetch": "empty"})
            continue

        v = verifier_score(case, law_name, article_title, article_text)
        score = v["score_total"]
        verdict = v["verdict"]

        item = {
            "cand": cand,
            "selected": {"law_name": law_name, "mst": mst, "link": link, "article_title": article_title},
            "article_text_preview": article_text[:240],
            "verify": v,
            "index": pack.get("index", [])[:80],
        }
        loop_debug.append(item)

        if score > best["score"]:
            best = {
                "law_name": law_name,
                "mst": mst,
                "link": link,
                "article_title": article_title,
                "article_text": strip_hanja_for_display(article_text),
                "index": pack.get("index", [])[:120],
                "verdict": verdict,
                "score": score,
                "verify": v,
            }

        if verdict == "CONFIRMED":
            break

    tend(t, {"best_score": best.get("score"), "verdict": best.get("verdict")})

    # 4) Case search (NAVER)
    t = tstart("CASE_SEARCH")
    case_query = build_case_query(case)
    items = naver.search(case_query, cat="news", display=10) if naver.enabled else []
    cases = []
    cases_text = ""
    for it in items:
        title = clean_text(it.get("title"))
        desc = clean_text(it.get("description"))
        link = clean_text(it.get("link"))
        cases.append({"title": title, "desc": desc, "link": link})
        cases_text += f"- {title}: {desc}\n"
    tend(t, {"query": case_query, "count": len(cases)})

    # 5) Strategy
    t = tstart("STRATEGY")
    strategy = draft_strategy(case, best, cases_text)
    tend(t)

    # 6) Draft JSON
    t = tstart("DRAFT_DOC")
    doc = draft_document_json(dept, officer, case, best, strategy)
    doc = ensure_doc_shape(doc)
    tend(t)

    return {
        "case": case,
        "candidates": candidates,
        "law_best": best,
        "law_loop": loop_debug,
        "cases": cases,
        "strategy": strategy,
        "doc": doc,
        "meta": doc.get("_meta", {}),
        "perf": st.session_state["metrics"],
    }


# =========================================================
# 9) UI Renderers
# =========================================================
def render_a4(doc: Dict[str, Any], meta: Dict[str, Any]) -> str:
    body_html = "".join(
        [f"<p style='margin:0 0 14px 0; text-indent: 10px;'>{safe_html(p)}</p>" for p in doc.get("body_paragraphs", [])]
    )
    html = f"""
<div class="paper-sheet" id="printable-area">
  <div class="stamp">ì§ì¸ìƒëµ</div>
  <div class="doc-header">{safe_html(doc.get('title',''))}</div>
  <div class="doc-info">
    <span><b>ë¬¸ì„œë²ˆí˜¸:</b> {safe_html(meta.get('doc_num',''))}</span>
    <span><b>ì‹œí–‰ì¼ì:</b> {safe_html(meta.get('today',''))}</span>
    <span><b>ìˆ˜ì‹ :</b> {safe_html(doc.get('receiver',''))}</span>
  </div>
  <div class="doc-body">
    {body_html}
    <div style="margin-top:20px; font-size:11pt; color:#374151;">
      <b>ë‹´ë‹¹:</b> {safe_html(meta.get('officer',''))} &nbsp; | &nbsp;
      <b>ë¶€ì„œ:</b> {safe_html(meta.get('dept',''))}
    </div>
  </div>
  <div class="doc-footer">{safe_html(doc.get('department_head',''))}</div>
</div>
"""
    components.html(html, height=980, scrolling=True)
    return html

def verdict_badge(verdict: str) -> str:
    v = (verdict or "").upper()
    if v == "CONFIRMED":
        return "<span class='badge ok'>CONFIRMED</span>"
    if v == "WEAK":
        return "<span class='badge warn'>WEAK</span>"
    return "<span class='badge fail'>FAIL</span>"

def render_perf(perf: Dict[str, Any]):
    calls = perf.get("calls", {})
    tokens_total = perf.get("tokens_total", 0)
    timings = perf.get("timings", [])
    cache_hits = perf.get("cache_hits", {})

    st.markdown("### âš¡ ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ(ëˆˆìœ¼ë¡œ í™•ì¸)")
    st.markdown(
        f"""
<div class="kpi">
  <div class="pill">LLM í˜¸ì¶œ: <b>{sum(calls.values())}</b></div>
  <div class="pill">í† í°(ê°€ëŠ¥ì‹œ): <b>{tokens_total}</b></div>
  <div class="pill">law_search cache-hit(ì¶”ì •): <b>{cache_hits.get('law_search',0)}</b></div>
  <div class="pill">law_service cache-hit(ì¶”ì •): <b>{cache_hits.get('law_service',0)}</b></div>
</div>
""",
        unsafe_allow_html=True,
    )

    if calls:
        st.markdown("**ëª¨ë¸ í˜¸ì¶œ íšŸìˆ˜**")
        st.json(calls)

    if timings:
        st.markdown("**ë‹¨ê³„ë³„ ì†Œìš”(ms)**")
        # í‘œë¡œ ë³´ê¸° ì¢‹ê²Œ
        rows = [{"step": x["step"], "ms": x["ms"], **(x.get("extra") or {})} for x in timings[-40:]]
        st.dataframe(rows, use_container_width=True, height=260)

def render_law_clickable(best: Dict[str, Any], loop: List[dict]):
    st.markdown("### ğŸ“š ë²•ë ¹ ê·¼ê±°(í´ë¦­í˜•)")
    if not best.get("law_name"):
        st.warning("ì„ íƒëœ ë²•ë ¹ì´ ì—†ìŠµë‹ˆë‹¤. ì…ë ¥ì„ ë” êµ¬ì²´í™”í•˜ê±°ë‚˜ í›„ë³´ ìƒì„±ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return

    st.markdown(
        f"""
<div class="card">
  <h4 style="margin:0;">{escape(best.get("law_name",""))} &nbsp; {verdict_badge(best.get("verdict",""))}</h4>
  <div class="muted">ì„ íƒ ì¡°ë¬¸: <b>{escape(best.get("article_title",""))}</b> &nbsp; | &nbsp; score: <b>{best.get("score",0)}</b></div>
</div>
""",
        unsafe_allow_html=True,
    )

    # 1) ì›ë¬¸ ë³´ê¸°
    with st.expander("âœ… [í´ë¦­] ì¡°ë¬¸ ì›ë¬¸ ë³´ê¸°", expanded=True):
        st.code(normalize_whitespace(best.get("article_text","")), language="text")
        if best.get("link"):
            st.markdown(f"- ë²•ë ¹ ìƒì„¸ ë§í¬: {best.get('link')}")

    # 2) ì¡°ë¬¸ ëª©ë¡(ì¸ë±ìŠ¤) í´ë¦­
    idx = best.get("index", []) or []
    if idx:
        with st.expander("ğŸ“‘ [í´ë¦­] ê°™ì€ ë²•ë ¹ì˜ ì¡°ë¬¸ ëª©ë¡(ì„ íƒ)", expanded=False):
            st.caption("ì›ë¬¸ì´ ê¸¸ê±°ë‚˜ í•„ìš”í•œ ì¡°ë¬¸ì´ ë‹¤ë¥¸ ê²½ìš° ì—¬ê¸°ì„œ ì¡°ë¬¸ë²ˆí˜¸ë¥¼ ê³¨ë¼ ë‹¤ì‹œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            options = []
            for it in idx[:120]:
                title = clean_text(it.get("title"))
                an = clean_text(it.get("article_no"))
                if an:
                    options.append(f"{an} | {title}")
                else:
                    options.append(f"? | {title}")

            sel = st.selectbox("ì¡°ë¬¸ ì„ íƒ", options, index=0)
            if st.button("ì„ íƒ ì¡°ë¬¸ ì›ë¬¸ ë‹¤ì‹œ ê°€ì ¸ì˜¤ê¸°", use_container_width=True):
                try:
                    mst = best.get("mst")
                    an = sel.split("|")[0].strip()
                    law_obj = law_api.get_law_object(mst)
                    pack = law_api.get_article_text(law_obj, article_no=an)
                    best["article_title"] = pack.get("article_title","")
                    best["article_text"] = pack.get("article_text","")
                    best["index"] = pack.get("index", [])[:120]
                    st.success("ì¡°ë¬¸ì„ ê°±ì‹ í–ˆìŠµë‹ˆë‹¤. ìœ„ ì›ë¬¸(expander)ì„ ë‹¤ì‹œ í™•ì¸í•˜ì„¸ìš”.")
                except Exception as e:
                    st.error(f"ì¡°ë¬¸ ê°±ì‹  ì‹¤íŒ¨: {e}")

    # 3) í›„ë³´/ê²€ì¦ ë¡œê·¸
    with st.expander("ğŸ” [í´ë¦­] ë²•ë ¹ í›„ë³´ + ê²€ì¦ ì ìˆ˜(ë£¨í”„ ë¡œê·¸)", expanded=False):
        if not loop:
            st.caption("ë£¨í”„ ë¡œê·¸ ì—†ìŒ")
        else:
            st.dataframe(
                [
                    {
                        "candidate": x.get("cand", {}).get("law_name"),
                        "article_hint": x.get("cand", {}).get("article_hint"),
                        "selected_law": x.get("selected", {}).get("law_name"),
                        "selected_article": x.get("selected", {}).get("article_title"),
                        "verdict": x.get("verify", {}).get("verdict"),
                        "score": x.get("verify", {}).get("score_total"),
                        "preview": x.get("article_text_preview",""),
                    }
                    for x in loop
                ],
                use_container_width=True,
                height=260,
            )

def render_cases_clickable(cases: List[dict]):
    st.markdown("### ğŸ§¾ ì‚¬ë¡€/ì°¸ê³ (í´ë¦­í˜•)")
    if not cases:
        st.info("ë„¤ì´ë²„ APIê°€ ì—†ê±°ë‚˜(ë¯¸ì„¤ì •), ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    st.caption("ë‹´ë‹¹ìê°€ íŒë‹¨í•  ìˆ˜ ìˆë„ë¡ 'í´ë¦­í•´ì„œ ì›ë¬¸ ë§í¬'ë¡œ í™•ì¸í•˜ì„¸ìš”.")
    for i, it in enumerate(cases[:10], start=1):
        title = clean_text(it.get("title"))
        desc = clean_text(it.get("desc"))
        link = clean_text(it.get("link"))
        if link:
            st.markdown(
                f"<div class='card'><div><b>{i}. <a href='{escape(link)}' target='_blank'>{escape(title)}</a></b></div>"
                f"<div class='muted'>{escape(desc)}</div></div>",
                unsafe_allow_html=True,
            )
        else:
            st.markdown(
                f"<div class='card'><div><b>{i}. {escape(title)}</b></div><div class='muted'>{escape(desc)}</div></div>",
                unsafe_allow_html=True,
            )


# =========================================================
# 10) Main UI
# =========================================================
def main():
    col_l, col_r = st.columns([1.0, 1.25], gap="large")

    with col_l:
        st.title("AI í–‰ì •ê´€ Pro v8")
        st.caption("í´ë¦­í˜• ê·¼ê±°(ì›ë¬¸/ì‚¬ë¡€) + Verifier + ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ")

        if not llm.ready():
            st.warning("Groq ì„¤ì •ì´ ì•„ì§ì…ë‹ˆë‹¤. secrets.tomlì— GROQ_API_KEYë¥¼ ë„£ì–´ì£¼ì„¸ìš”.")
        if not law_api.enabled:
            st.warning("LAW.go.kr DRF ì„¤ì •ì´ ì•„ì§ì…ë‹ˆë‹¤. secrets.tomlì— LAW_API_ID + requirements(xmltodict/requests) í™•ì¸")
        st.markdown("---")

        with st.expander("âš™ï¸ ì„¤ì •", expanded=False):
            st.text_input("ë¶€ì„œëª…", key="dept")
            st.text_input("ë‹´ë‹¹ì", key="officer")
            st.text_input("ì‚¬ìš©ì í‚¤(êµ¬ë¶„ìš©)", key="user_key")
            st.caption("â€» Streamlit Cloud: Settings â†’ Secretsì— keysë¥¼ ë„£ì–´ì•¼ í•©ë‹ˆë‹¤.")

        user_input = st.text_area(
            "ë¯¼ì›/ì—…ë¬´ ì§€ì‹œ(ìƒí™© í¬í•¨)",
            height=240,
            placeholder="ì˜ˆ: ê±´ì„¤ê¸°ê³„ ì°¨ê³ ì§€ ì™¸ ì¥ê¸° ì£¼ì°¨(ì£¼ê¸°ìœ„ë°˜) ì‹ ê³ . í˜„ì¥ í™•ì¸í–ˆìœ¼ë‚˜ í˜„ì¬ëŠ” ì´ë™. ë¯¼ì›ì¸ì€ ìƒì‹œ ë‹¨ì† ìš”êµ¬. ë‹´ë‹¹ìê°€ í•  ìˆ˜ ìˆëŠ” ì¡°ì¹˜ì™€ ë‹µë³€ ê³µë¬¸ ì‘ì„±.",
        )

        run = st.button("ğŸš€ ì‹¤í–‰(ê·¼ê±°/ì‚¬ë¡€/ê³µë¬¸ ìƒì„±)", type="primary", use_container_width=True)

        st.markdown("---")
        st.subheader("ğŸ§  ì‚¬ìš© íŒ(ì„±ëŠ¥/ì •í™•ë„)")
        st.markdown(
            "- **what(ë¬´ìŠ¨ ì¼ì´ ìˆì—ˆëŠ”ì§€)**ë¥¼ 1~2ë¬¸ì¥ìœ¼ë¡œ ì •í™•íˆ\n"
            "- **where/when**ì´ ì—†ìœ¼ë©´ ë²•ë ¹/ì ˆì°¨ê°€ í”ë“¤ë¦¼\n"
            "- ì¦ê±°ê°€ ìˆìœ¼ë©´(evidence) ëª…ì‹œ(ì‚¬ì§„/ì˜ìƒ/ì§„ìˆ )\n"
            "- ê²°ê³¼ì—ì„œ **ë²•ë ¹ ì›ë¬¸/ì‚¬ë¡€ ë§í¬ë¥¼ í´ë¦­**í•´ì„œ íŒë‹¨",
        )

        if run:
            if not user_input.strip():
                st.warning("ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”.")
            else:
                try:
                    # ë§¤ ì‹¤í–‰ë§ˆë‹¤ timings ì´ˆê¸°í™”(ë¹„êµê°€ ì‰¬ì›€)
                    st.session_state["metrics"]["timings"] = []
                    with st.spinner("INTAKE â†’ í›„ë³´ â†’ ì›ë¬¸í™•ë³´ â†’ ê²€ì¦ â†’ ì‚¬ë¡€ â†’ ê³µë¬¸ ìƒì„± ì¤‘..."):
                        res = run_workflow(user_input.strip(), st.session_state["dept"], st.session_state["officer"])
                        st.session_state["result"] = res
                        st.session_state["selected_law"] = res.get("law_best")
                        st.success("ì™„ë£Œ!")
                except Exception as e:
                    st.session_state["last_error"] = str(e)
                    st.error(f"ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
                    st.exception(e)

        # ì™¼ìª½ ì•„ë˜: ì˜¤ë¥˜ íŒíŠ¸
        if st.session_state.get("last_error"):
            st.error("ìµœê·¼ ì˜¤ë¥˜")
            st.code(st.session_state["last_error"])

    with col_r:
        tab1, tab2, tab3 = st.tabs(["ğŸ“„ A4 ê³µë¬¸", "ğŸ“š ê·¼ê±°/ì‚¬ë¡€(í´ë¦­)", "âš¡ ì„±ëŠ¥/ë””ë²„ê·¸"])

        res = st.session_state.get("result")

        with tab1:
            if not res:
                st.markdown(
                    """
<div style="text-align:center; padding:120px 20px; color:#9ca3af; border:2px dashed #e5e7eb; border-radius:14px; background:#fff;">
  <h3 style="margin-bottom:8px;">ğŸ“„ A4 ê³µë¬¸ ë¯¸ë¦¬ë³´ê¸°</h3>
  <p>ì™¼ìª½ì—ì„œ ë¯¼ì› ìƒí™©ì„ ì…ë ¥í•˜ê³  ì‹¤í–‰ì„ ëˆ„ë¥´ì„¸ìš”.<br>ìë™ìœ¼ë¡œ ê·¼ê±°/ì‚¬ë¡€ë¥¼ ëª¨ì•„ ê³µë¬¸ì„ ì‘ì„±í•©ë‹ˆë‹¤.</p>
</div>
""",
                    unsafe_allow_html=True,
                )
            else:
                html = render_a4(res["doc"], res.get("meta", {}))
                st.session_state["raw_last_html"] = html
                st.download_button(
                    "ğŸ“¥ ê³µë¬¸ HTML ë‹¤ìš´ë¡œë“œ",
                    data=html.encode("utf-8"),
                    file_name=f"ê³µë¬¸_{res.get('meta',{}).get('doc_num','')}.html",
                    mime="text/html",
                    use_container_width=True,
                )

        with tab2:
            if not res:
                st.info("ê²°ê³¼ê°€ ì•„ì§ ì—†ìŠµë‹ˆë‹¤.")
            else:
                # 1) ê·¼ê±°
                render_law_clickable(res.get("law_best", {}), res.get("law_loop", []))
                st.markdown("---")
                # 2) ì‚¬ë¡€
                render_cases_clickable(res.get("cases", []))
                st.markdown("---")
                # 3) ì²˜ë¦¬ ì „ëµ
                st.markdown("### âœ… ì²˜ë¦¬ ì „ëµ(ìš”ì•½)")
                st.markdown(res.get("strategy", ""))

        with tab3:
            if not res:
                st.info("ê²°ê³¼ê°€ ì•„ì§ ì—†ìŠµë‹ˆë‹¤.")
            else:
                render_perf(res.get("perf", {}))
                with st.expander("ğŸ§¾ êµ¬ì¡°í™”(Intake) ì›ë¬¸ JSON", expanded=False):
                    st.code(jdump(res.get("case", {})), language="json")
                with st.expander("ğŸ§© ë²•ë ¹ í›„ë³´ ìƒì„± ê²°ê³¼", expanded=False):
                    st.code(jdump(res.get("candidates", [])), language="json")
                with st.expander("ğŸ ìµœì¢… ë²•ë ¹ pack", expanded=False):
                    st.code(jdump(res.get("law_best", {})), language="json")

if __name__ == "__main__":
    main()
